{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tumor Multi-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the libraries first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(309, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>histologic-type</th>\n",
       "      <th>degree-of-diffe</th>\n",
       "      <th>bone</th>\n",
       "      <th>bone-marrow</th>\n",
       "      <th>lung</th>\n",
       "      <th>pleura</th>\n",
       "      <th>peritoneum</th>\n",
       "      <th>liver</th>\n",
       "      <th>brain</th>\n",
       "      <th>skin</th>\n",
       "      <th>neck</th>\n",
       "      <th>supraclavicular</th>\n",
       "      <th>axillar</th>\n",
       "      <th>mediastinum</th>\n",
       "      <th>abdominal</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&gt;=60</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>lung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;=60</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>poorly</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>lung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30-59</td>\n",
       "      <td>female</td>\n",
       "      <td>adefalse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>breast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30-59</td>\n",
       "      <td>female</td>\n",
       "      <td>adefalse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ovary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30-59</td>\n",
       "      <td>female</td>\n",
       "      <td>adefalse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ovary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age     sex histologic-type degree-of-diffe   bone  bone-marrow   lung  \\\n",
       "0   >=60  female             NaN             NaN  False        False  False   \n",
       "1   >=60    male             NaN          poorly  False        False  False   \n",
       "2  30-59  female        adefalse             NaN  False        False  False   \n",
       "3  30-59  female        adefalse             NaN  False        False  False   \n",
       "4  30-59  female        adefalse             NaN  False        False  False   \n",
       "\n",
       "   pleura  peritoneum  liver  brain   skin   neck  supraclavicular axillar  \\\n",
       "0   False       False   True  False  False  False            False   False   \n",
       "1   False       False   True  False  False  False             True   False   \n",
       "2    True       False  False  False   True  False            False    True   \n",
       "3   False        True  False  False  False  False            False   False   \n",
       "4    True        True  False  False  False  False            False   False   \n",
       "\n",
       "   mediastinum  abdominal   class  \n",
       "0        False      False    lung  \n",
       "1         True      False    lung  \n",
       "2        False      False  breast  \n",
       "3        False      False   ovary  \n",
       "4        False      False   ovary  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'D:\\joel\\UDEMY -\\datasets and codes\\Notebooks\\.ipynb_checkpoints\\tumor data\\tumorData.csv')\n",
    "print (df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a dataset of individual Tumor observations with various features classifying a different class/location of cancer.\n",
    "Let's look at the counts of observations present for different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lung                 26.213592\n",
      "stomach              12.297735\n",
      "pancreas              9.061489\n",
      "kidney                7.443366\n",
      "ovary                 6.148867\n",
      "breast                5.825243\n",
      "gallbladder           4.854369\n",
      "head and neck         4.530744\n",
      "thyroid               4.530744\n",
      "colon                 4.530744\n",
      "esophagus             2.912621\n",
      "prostate              2.588997\n",
      "liver                 2.265372\n",
      "rectum                1.941748\n",
      "corpus uteri          1.941748\n",
      "salivary glands       0.647249\n",
      "cervix uteri          0.647249\n",
      "bladder               0.647249\n",
      "vagina                0.323625\n",
      "testis                0.323625\n",
      "duoden and sm.int     0.323625\n",
      "Name: class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print ((df['class'].value_counts()/df.shape[0])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see some of the classes have less than 1% i.e; less than 6 observations associated with them. We need to remove them now even before we can perform any kind of analysis, impuation or oversampling, because there's not much we can do with these classes that have maybe 1 or 2 sample associated with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lung                 81\n",
       "stomach              38\n",
       "pancreas             28\n",
       "kidney               23\n",
       "ovary                19\n",
       "breast               18\n",
       "gallbladder          15\n",
       "head and neck        14\n",
       "thyroid              14\n",
       "colon                14\n",
       "esophagus             9\n",
       "prostate              8\n",
       "liver                 7\n",
       "rectum                6\n",
       "corpus uteri          6\n",
       "salivary glands       2\n",
       "cervix uteri          2\n",
       "bladder               2\n",
       "vagina                1\n",
       "testis                1\n",
       "duoden and sm.int     1\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below class observations we shall remove from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lung             81\n",
       "stomach          38\n",
       "pancreas         28\n",
       "kidney           23\n",
       "ovary            19\n",
       "breast           18\n",
       "gallbladder      15\n",
       "head and neck    14\n",
       "thyroid          14\n",
       "colon            14\n",
       "esophagus         9\n",
       "prostate          8\n",
       "liver             7\n",
       "corpus uteri      6\n",
       "rectum            6\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for c in ['salivary glands','cervix uteri','bladder','vagina','testis','duoden and sm.int']: \n",
    "    df.drop(df[df['class']==c].index,inplace=True) \n",
    "\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for the presence of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                 0.00\n",
      "sex                 0.33\n",
      "histologic-type    21.00\n",
      "degree-of-diffe    44.67\n",
      "bone                0.00\n",
      "bone-marrow         0.00\n",
      "lung                0.00\n",
      "pleura              0.00\n",
      "peritoneum          0.00\n",
      "liver               0.00\n",
      "brain               0.00\n",
      "skin                0.33\n",
      "neck                0.00\n",
      "supraclavicular     0.00\n",
      "axillar             0.33\n",
      "mediastinum         0.00\n",
      "abdominal           0.00\n",
      "class               0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print (round((df.isnull().sum()/df.shape[0])*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are missing values, especially very highly in the 'degree-of-diffe' variable followed by 'histologic-type'.\n",
    "We will remove the 'degree-of-diffe' variable because 44% missing value percentage is above the 30% limit for the presence of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 17)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['degree-of-diffe'],axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do any imputation over missing, we need to first encode the categorical string classes to categorical numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abdominal': {False: 0, True: 1},\n",
      " 'age': {'30-59': 0, '<30': 1, '>=60': 2},\n",
      " 'axillar': {False: 0, True: 1, nan: -1},\n",
      " 'bone': {False: 0, True: 1},\n",
      " 'bone-marrow': {False: 0, True: 1},\n",
      " 'brain': {False: 0, True: 1},\n",
      " 'class': {'breast': 0,\n",
      "           'colon': 1,\n",
      "           'corpus uteri': 2,\n",
      "           'esophagus': 3,\n",
      "           'gallbladder': 4,\n",
      "           'head and neck': 5,\n",
      "           'kidney': 6,\n",
      "           'liver': 7,\n",
      "           'lung': 8,\n",
      "           'ovary': 9,\n",
      "           'pancreas': 10,\n",
      "           'prostate': 11,\n",
      "           'rectum': 12,\n",
      "           'stomach': 13,\n",
      "           'thyroid': 14},\n",
      " 'histologic-type': {nan: -1, 'adefalse': 0, 'anaplastic': 1, 'epidermoid': 2},\n",
      " 'liver': {False: 0, True: 1},\n",
      " 'lung': {False: 0, True: 1},\n",
      " 'mediastinum': {False: 0, True: 1},\n",
      " 'neck': {False: 0, True: 1},\n",
      " 'peritoneum': {False: 0, True: 1},\n",
      " 'pleura': {False: 0, True: 1},\n",
      " 'sex': {nan: -1, 'female': 0, 'male': 1},\n",
      " 'skin': {False: 0, True: 1, nan: -1},\n",
      " 'supraclavicular': {False: 0, True: 1}}\n",
      "   age  sex  histologic-type  bone  bone-marrow  lung  pleura  peritoneum  \\\n",
      "0    2  0.0              NaN     0            0     0       0           0   \n",
      "1    2  1.0              NaN     0            0     0       0           0   \n",
      "2    0  0.0              0.0     0            0     0       1           0   \n",
      "3    0  0.0              0.0     0            0     0       0           1   \n",
      "4    0  0.0              0.0     0            0     0       1           1   \n",
      "\n",
      "   liver  brain  skin  neck  supraclavicular  axillar  mediastinum  abdominal  \\\n",
      "0      1      0   0.0     0                0      0.0            0          0   \n",
      "1      1      0   0.0     0                1      0.0            1          0   \n",
      "2      0      0   1.0     0                0      1.0            0          0   \n",
      "3      0      0   0.0     0                0      0.0            0          0   \n",
      "4      0      0   0.0     0                0      0.0            0          0   \n",
      "\n",
      "   class  \n",
      "0      8  \n",
      "1      8  \n",
      "2      0  \n",
      "3      9  \n",
      "4      9  \n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "encodings= {} # create a dictionary fo refering the original class names.\n",
    "for c in df.columns:\n",
    "    old_values = df[c].unique()\n",
    "    encodings[c]={}\n",
    "    df[c] = pd.Categorical(df[c])\n",
    "    df[c] = df[c].cat.codes\n",
    "    df[c] = df[c].astype('object')   \n",
    "    new_values = df[c].unique()\n",
    "    for i in range(len(old_values)):\n",
    "        encodings[c][old_values[i]]=new_values[i]\n",
    "\n",
    "pprint.pprint(encodings)\n",
    "\n",
    "df = df.replace(-1,np.NaN) # replace them with original Null values, else they won't be imputed correctly\n",
    "print (df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead with the Data imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                0\n",
       "sex                0\n",
       "histologic-type    0\n",
       "bone               0\n",
       "bone-marrow        0\n",
       "lung               0\n",
       "pleura             0\n",
       "peritoneum         0\n",
       "liver              0\n",
       "brain              0\n",
       "skin               0\n",
       "neck               0\n",
       "supraclavicular    0\n",
       "axillar            0\n",
       "mediastinum        0\n",
       "abdominal          0\n",
       "class              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "df_array = np.array(df)\n",
    "df = pd.DataFrame(data = np.round(imputer.fit_transform(df_array)),columns = df.columns)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform some hypothesis test for checking the relationships of independent variables w.r.t the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Squared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrelated:  ['bone-marrow', 'pleura', 'brain', 'skin']\n",
      "related:  ['age', 'sex', 'histologic-type', 'bone', 'lung', 'peritoneum', 'liver', 'neck', 'supraclavicular', 'axillar', 'mediastinum', 'abdominal']\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "Chi_unrelated = []\n",
    "Chi_related = []\n",
    "\n",
    "for i in df.columns[:-1]:\n",
    "    chi2, p, dof, ex = chi2_contingency(pd.crosstab(df['class'], df[i]))\n",
    "    if p>0.05:\n",
    "        Chi_unrelated.append(i)\n",
    "    else:\n",
    "        Chi_related.append(i)\n",
    "\n",
    "print ('unrelated: ',Chi_unrelated)\n",
    "print ('related: ',Chi_related)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import ExtraTreeClassifier as ET\n",
    "importance = ET().fit(df.iloc[:,:-1],df['class'])\n",
    "\n",
    "values = pd.Series(importance.feature_importances_,index=df.columns[:-1])\n",
    "values.nlargest(df.shape[1]-1).plot(kind='bar')\n",
    "plt.figsize=(10,15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a list of the 6 least important features selected by this trees based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bone-marrow', 'brain', 'supraclavicular', 'skin', 'axillar', 'pleura']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ET_unimportant = list(values.nsmallest(6).index)\n",
    "ET_unimportant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "important features:  ['sex', 'histologic-type', 'bone', 'liver', 'neck', 'abdominal']\n",
      "unimportant:  ['age', 'bone-marrow', 'lung', 'pleura', 'peritoneum', 'brain', 'skin', 'supraclavicular', 'axillar', 'mediastinum', 'class']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "sel_ = SelectFromModel(LogisticRegression(penalty='l2'))\n",
    "sel_.fit(df.iloc[:,:-1],df['class'])\n",
    "\n",
    "RR_important = list(df.columns[:-1][sel_.get_support()])\n",
    "RR_unimportant = [i for i in df.columns if i not in RR_important]\n",
    "print ('important features: ',RR_important)\n",
    "print ('unimportant: ',RR_unimportant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "important features:  Index(['age', 'sex', 'histologic-type', 'lung', 'peritoneum', 'liver',\n",
      "       'mediastinum', 'abdominal'],\n",
      "      dtype='object')\n",
      "unimportant:  ['bone', 'bone-marrow', 'pleura', 'brain', 'skin', 'neck', 'supraclavicular', 'axillar', 'class']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "sel_ = SelectFromModel(RandomForestClassifier())\n",
    "sel_.fit(df.iloc[:,:-1],df['class'])\n",
    "\n",
    "RF_important = df.columns[:-1][sel_.get_support()]\n",
    "RF_unimportant = [i for i in df.columns if i not in RF_important]\n",
    "print ('important features: ',RF_important)\n",
    "print ('unimportant: ',RF_unimportant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Let's look at the unimportant features deemed by these different tests\n",
    "Random Forests: ['bone', 'bone-marrow', 'pleura', 'peritoneum', 'liver', 'brain', 'skin', 'neck', 'supraclavicular', 'axillar', 'class']\n",
    "Ridge Regression: ['age', 'bone-marrow', 'lung', 'pleura', 'peritoneum', 'brain', 'skin', 'supraclavicular', 'axillar', 'mediastinum', 'class']\n",
    "Extra trees classifier: ['bone-marrow', 'bone', 'brain', 'peritoneum', 'sex', 'skin']\n",
    "Chi-Squared: ['bone-marrow', 'pleura', 'brain', 'skin']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'skin': 4/4 , 'brain': 4/4, 'bone-marrow': 4/4,'pleura': 3/4, 'peritoneum': 2/4, 'liver':2/4(and many other with 2/4)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above list, we can take a chance of removing 'skin','pleura','brain','bone-marrow'  variables from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>histologic-type</th>\n",
       "      <th>bone</th>\n",
       "      <th>lung</th>\n",
       "      <th>peritoneum</th>\n",
       "      <th>liver</th>\n",
       "      <th>neck</th>\n",
       "      <th>supraclavicular</th>\n",
       "      <th>axillar</th>\n",
       "      <th>mediastinum</th>\n",
       "      <th>abdominal</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  histologic-type  bone  lung  peritoneum  liver  neck  \\\n",
       "0  2.0  0.0              1.0   0.0   0.0         0.0    1.0   0.0   \n",
       "1  2.0  1.0              2.0   0.0   0.0         0.0    1.0   0.0   \n",
       "2  0.0  0.0              0.0   0.0   0.0         0.0    0.0   0.0   \n",
       "3  0.0  0.0              0.0   0.0   0.0         1.0    0.0   0.0   \n",
       "4  0.0  0.0              0.0   0.0   0.0         1.0    0.0   0.0   \n",
       "\n",
       "   supraclavicular  axillar  mediastinum  abdominal  class  \n",
       "0              0.0      0.0          0.0        0.0    8.0  \n",
       "1              1.0      0.0          1.0        0.0    8.0  \n",
       "2              0.0      1.0          0.0        0.0    0.0  \n",
       "3              0.0      0.0          0.0        0.0    9.0  \n",
       "4              0.0      0.0          0.0        0.0    9.0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.drop(['skin','pleura','brain','bone-marrow'],axis=1)\n",
    "print (df2.shape)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing before we develop any models over the train data, we need to One-hot encode both the training & the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first check the unique value of every variable and which variables need one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age :  [2. 0. 1.]\n",
      "sex :  [0. 1.]\n",
      "histologic-type :  [1. 2. 0.]\n",
      "bone :  [0. 1.]\n",
      "lung :  [0. 1.]\n",
      "peritoneum :  [0. 1.]\n",
      "liver :  [1. 0.]\n",
      "neck :  [0. 1.]\n",
      "supraclavicular :  [0. 1.]\n",
      "axillar :  [0. 1.]\n",
      "mediastinum :  [0. 1.]\n",
      "abdominal :  [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "for i in df2.columns[:-1]:\n",
    "    print (i,': ',df2[i].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see 'age' & 'histologic type' variables need one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (300, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>bone</th>\n",
       "      <th>lung</th>\n",
       "      <th>peritoneum</th>\n",
       "      <th>liver</th>\n",
       "      <th>neck</th>\n",
       "      <th>supraclavicular</th>\n",
       "      <th>axillar</th>\n",
       "      <th>mediastinum</th>\n",
       "      <th>abdominal</th>\n",
       "      <th>age_0.0</th>\n",
       "      <th>age_1.0</th>\n",
       "      <th>age_2.0</th>\n",
       "      <th>histologic-type_0.0</th>\n",
       "      <th>histologic-type_1.0</th>\n",
       "      <th>histologic-type_2.0</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  bone  lung  peritoneum  liver  neck  supraclavicular  axillar  \\\n",
       "0  0.0   0.0   0.0         0.0    1.0   0.0              0.0      0.0   \n",
       "1  1.0   0.0   0.0         0.0    1.0   0.0              1.0      0.0   \n",
       "2  0.0   0.0   0.0         0.0    0.0   0.0              0.0      1.0   \n",
       "3  0.0   0.0   0.0         1.0    0.0   0.0              0.0      0.0   \n",
       "4  0.0   0.0   0.0         1.0    0.0   0.0              0.0      0.0   \n",
       "5  1.0   0.0   0.0         0.0    1.0   0.0              0.0      0.0   \n",
       "6  1.0   1.0   0.0         0.0    0.0   0.0              0.0      0.0   \n",
       "7  0.0   1.0   0.0         0.0    0.0   0.0              0.0      0.0   \n",
       "8  1.0   0.0   0.0         0.0    0.0   1.0              1.0      0.0   \n",
       "9  0.0   0.0   0.0         1.0    1.0   0.0              0.0      0.0   \n",
       "\n",
       "   mediastinum  abdominal  age_0.0  age_1.0  age_2.0  histologic-type_0.0  \\\n",
       "0          0.0        0.0      0.0      0.0      1.0                  0.0   \n",
       "1          1.0        0.0      0.0      0.0      1.0                  0.0   \n",
       "2          0.0        0.0      1.0      0.0      0.0                  1.0   \n",
       "3          0.0        0.0      1.0      0.0      0.0                  1.0   \n",
       "4          0.0        0.0      1.0      0.0      0.0                  1.0   \n",
       "5          0.0        0.0      1.0      0.0      0.0                  1.0   \n",
       "6          0.0        0.0      1.0      0.0      0.0                  1.0   \n",
       "7          1.0        0.0      1.0      0.0      0.0                  1.0   \n",
       "8          0.0        0.0      1.0      0.0      0.0                  1.0   \n",
       "9          0.0        0.0      1.0      0.0      0.0                  1.0   \n",
       "\n",
       "   histologic-type_1.0  histologic-type_2.0  class  \n",
       "0                  1.0                  0.0    8.0  \n",
       "1                  0.0                  1.0    8.0  \n",
       "2                  0.0                  0.0    0.0  \n",
       "3                  0.0                  0.0    9.0  \n",
       "4                  0.0                  0.0    9.0  \n",
       "5                  0.0                  0.0    1.0  \n",
       "6                  0.0                  0.0   11.0  \n",
       "7                  0.0                  0.0    8.0  \n",
       "8                  0.0                  0.0   11.0  \n",
       "9                  0.0                  0.0    9.0  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "\n",
    "ohe_columns = ['age','histologic-type']\n",
    "base_columns = [i for i in df2.columns[:-1] if i not in ohe_columns]\n",
    "\n",
    "# Define a function that will intake the raw dataframe and the column name and return a one hot encoded DF\n",
    "def create_ohe(DF, col):\n",
    "    le = LabelEncoder()\n",
    "    a = le.fit_transform(DF[col]).reshape(-1,1)\n",
    "    ohe = OneHotEncoder(sparse=False)\n",
    "    column_names = [col+ \"_\"+ str(i) for i in le.classes_]\n",
    "    return(pd.DataFrame(ohe.fit_transform(a),columns =column_names))\n",
    "\n",
    "#Since the above function converts the column, one at a time\n",
    "#We create a loop to create the final dataset with all features\n",
    "temp = df2[base_columns]\n",
    "for column in ohe_columns:\n",
    "    temp_df = create_ohe(df2,column)\n",
    "    temp = pd.concat([temp,temp_df],axis=1)\n",
    "\n",
    "temp = pd.concat([temp,df2['class']],axis=1)\n",
    "    \n",
    "    \n",
    "print(\"Shape of data:\",temp.shape)\n",
    "temp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check is the One-Hot-encoding made an missing values by mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex                    0\n",
       "bone                   0\n",
       "lung                   0\n",
       "peritoneum             0\n",
       "liver                  0\n",
       "neck                   0\n",
       "supraclavicular        0\n",
       "axillar                0\n",
       "mediastinum            0\n",
       "abdominal              0\n",
       "age_0.0                0\n",
       "age_1.0                0\n",
       "age_2.0                0\n",
       "histologic-type_0.0    0\n",
       "histologic-type_1.0    0\n",
       "histologic-type_2.0    0\n",
       "class                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the SMOTE algorithm to create new synthetic datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1215, 16) (1215,)\n",
      "Counter({8.0: 81, 0.0: 81, 9.0: 81, 1.0: 81, 11.0: 81, 5.0: 81, 14.0: 81, 10.0: 81, 7.0: 81, 6.0: 81, 12.0: 81, 4.0: 81, 13.0: 81, 3.0: 81, 2.0: 81})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(temp.iloc[:,:-1,],temp['class'])\n",
    "print (X.shape,y.shape)\n",
    "print (Counter(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into train & test before we balance the data & oversample it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:  (850, 16) (850,)\n",
      "Testing shape:  (365, 16) (365,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "# Let's split the data into train & test before oversampling the training data\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,train_size=0.7)\n",
    "print ('Training shape: ',X_train.shape,y_train.shape)\n",
    "print ('Testing shape: ',X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's oversample the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1700, 16) (1700,)\n"
     ]
    }
   ],
   "source": [
    "X,Y=[],[]\n",
    "\n",
    "for i in set(y_train):\n",
    "    X_obs = X_train[y_train==i]\n",
    "    for c in range(2):\n",
    "        X.append(X_obs)\n",
    "    Y = Y + [i]*2*len(X_obs)\n",
    "    \n",
    "X = np.vstack(X)    \n",
    "Y = np.array(Y)  \n",
    "print (X.shape,Y.shape)\n",
    "X,Y = shuffle(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the value counts of training targets before and after oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWUElEQVR4nO3dfZAcd33n8fcHyz5jY84SXgn54SLgVD4MF2zfFgGcojgLJw44lg2YgsI5HTHRccVjOCroQo7AJVQ5wZfjoShSKsAIMCaOH2LD5cA6XQzkAoa1kUHGEPFgjLGQ1iaExwIM3/ujW8VqtSuNVt2zWvr9qprq6Z7u73x3duczvT3Tv0lVIUkajocsdgOSpPEy+CVpYAx+SRoYg1+SBsbgl6SBWbbYDYzipJNOqjVr1ix2G5K0pNx22233V9XE7OVLIvjXrFnD1NTUYrchSUtKkq/PtdxDPZI0MAa/JA2MwS9JA2PwS9LAGPySNDAGvyQNjMEvSQNj8EvSwPQa/El+P8mdSXYkuTrJsUlWJNmaZGc7Xd5nD5KkffV25m6SU4CXA2dU1Y+SXAM8DzgD2FZVlyfZBGwCXtNXH9KR6Levvb6TOh96zrM6qaNh6ftQzzLgoUmWAccB9wHrgS3t7VuAi3ruQZI0Q2/BX1XfBK4A7gF2Af9cVTcDq6pqV7vOLmDlXNsn2ZhkKsnU9PR0X21K0uD0Fvztsfv1wKOAk4Hjk1w66vZVtbmqJqtqcmJiv8HlJEkL1OehnqcDX6uq6ar6KXA98BRgd5LVAO10T489SJJm6TP47wGelOS4JAHWAXcBNwEb2nU2ADf22IMkaZbePtVTVbcmuRa4HXgQ+CywGXgYcE2Sy2heHC7pqwdJ0v56/SKWqvpj4I9nLf4xzd6/JGkReOauJA2MwS9JA2PwS9LAGPySNDAGvyQNjMEvSQNj8EvSwBj8kjQwBr8kDYzBL0kDY/BL0sAY/JI0MAa/JA2MwS9JA2PwS9LAGPySNDAGvyQNTG/Bn+T0JNtnXL6b5JVJViTZmmRnO13eVw+SpP31FvxV9aWqOrOqzgT+HfBD4AZgE7CtqtYC29p5SdKYjOtQzzrgK1X1dWA9sKVdvgW4aEw9SJIYX/A/D7i6vb6qqnYBtNOVc22QZGOSqSRT09PTY2pTkn759R78SY4BLgT++lC2q6rNVTVZVZMTExP9NCdJAzSOPf7fAm6vqt3t/O4kqwHa6Z4x9CBJao0j+J/PLw7zANwEbGivbwBuHEMPkqRWr8Gf5DjgPOD6GYsvB85LsrO97fI+e5Ak7WtZn8Wr6ofAI2Yte4DmUz6SpEXgmbuSNDAGvyQNjMEvSQNj8EvSwBj8kjQwBr8kDYzBL0kDY/BL0sAY/JI0MAa/JA2MwS9JA2PwS9LAGPySNDAGvyQNjMEvSQNj8EvSwPT9DVwnJrk2yReT3JXkyUlWJNmaZGc7Xd5nD5KkffW9x/8W4CNV9W+AJwB3AZuAbVW1FtjWzkuSxqS34E/ycOCpwLsAquonVfUdYD2wpV1tC3BRXz1IkvbX5x7/o4Fp4Mokn03yziTHA6uqahdAO10518ZJNiaZSjI1PT3dY5uSNCx9Bv8y4GzgHVV1FvADDuGwTlVtrqrJqpqcmJjoq0dJGpw+g/9e4N6qurWdv5bmhWB3ktUA7XRPjz1IkmbpLfir6lvAN5Kc3i5aB3wBuAnY0C7bANzYVw+SpP0t67n+y4CrkhwDfBV4Ic2LzTVJLgPuAS7puQdJ0gy9Bn9VbQcm57hpXZ/3K0man2fuStLAGPySNDAGvyQNjMEvSQNj8EvSwBj8kjQwBr8kDYzBL0kDY/BL0sAY/JI0MAa/JA2MwS9JA2PwS9LAGPySNDAGvyQNjMEvSQNj8EvSwPT6DVxJ7ga+B/wMeLCqJpOsAP4KWAPcDTy3qv6pzz4kSb8wjj3+f19VZ1bV3q9g3ARsq6q1wLZ2XpI0JotxqGc9sKW9vgW4aBF6kKTB6jv4C7g5yW1JNrbLVlXVLoB2unKuDZNsTDKVZGp6errnNiVpOHo9xg+cU1X3JVkJbE3yxVE3rKrNwGaAycnJ6qtBSRqaXvf4q+q+droHuAF4IrA7yWqAdrqnzx4kSfvqLfiTHJ/khL3Xgd8AdgA3ARva1TYAN/bVgyRpf30e6lkF3JBk7/18oKo+kuQzwDVJLgPuAS7psQdJ0iy9BX9VfRV4whzLHwDW9XW/kqQD88xdSRoYg1+SBmak4E+ybZRlkqQj3wGP8Sc5FjgOOCnJciDtTQ8HTu65N0lSDw725u5/Al5JE/K38Yvg/y7w9v7akiT15YDBX1VvAd6S5GVV9bYx9SRJ6tFIH+esqrcleQrNUMrLZix/b099SZJ6MlLwJ3kf8BhgO83Y+tAMwGbwS9ISM+oJXJPAGVXlYGmStMSN+jn+HcAj+2xEkjQeo+7xnwR8IcmngR/vXVhVF/bSlSSpN6MG/+v7bEKSND6jfqrnY303Ikkaj1E/1fM9mk/xABwDHA38oKoe3ldjkqR+jLrHf8LM+SQX0XybliRpiVnQ6JxV9TfAud22Ikkah1EP9TxrxuxDaD7XP9Jn+pMcBUwB36yqC5KsAP6K5izgu4HnVtU/HULPkqTDMOoe/2/PuPwm8D1g/YjbvgK4a8b8JmBbVa0FtrXzkqQxGfUY/wsXUjzJqcAzgTcCr2oXrwee1l7fAtwCvGYh9SVJh27UL2I5NckNSfYk2Z3kujbUD+bNwB8AP5+xbFVV7QJopysPtWlJ0sKNeqjnSuAmmnH5TwE+1C6bV5ILgD1VddtCGkuyMclUkqnp6emFlJAkzWHU4J+oqiur6sH28h5g4iDbnANcmORu4IPAuUneD+xOshqgne6Za+Oq2lxVk1U1OTFxsLuSJI1q1OC/P8mlSY5qL5cCDxxog6r6r1V1alWtAZ4H/N+qupTmP4cN7WobgBsX2LskaQFGDf7fBZ4LfAvYBTwHWNAbvsDlwHlJdgLntfOSpDEZdZC2PwE27P28fftZ/CtoXhAOqqpuofn0DlX1ALDuUBuVJHVj1OD/1ZknWVXVt5Oc1VNPknTE+tYVX+6kziNf/a87qbMQox7qeUiS5Xtn2j3+UV80JElHkFHD+38A/5DkWpqhGp5Lc1KWJGmJGfXM3fcmmaIZmC3As6rqC712JknqxciHa9qgN+wlaYlb0LDMkqSly+CXpIEx+CVpYAx+SRoYg1+SBsbgl6SBMfglaWAMfkkaGINfkgbG4JekgTH4JWlgDH5JGpjegj/JsUk+neSOJHcmeUO7fEWSrUl2ttPlB6slSepOn3v8PwbOraonAGcC5yd5ErAJ2FZVa4Ft7bwkaUx6C/5qfL+dPbq9FLAe2NIu3wJc1FcPkqT99XqMP8lRSbYDe4CtVXUrsKqqdgG005XzbLsxyVSSqenp6T7blKRB6TX4q+pnVXUmcCrwxCSPP4RtN1fVZFVNTkxM9NajJA3NWD7VU1XfAW4Bzgd2J1kN0E73jKMHSVKjz0/1TCQ5sb3+UODpwBeBm4AN7WobgBv76kGStL+Rv3N3AVYDW5IcRfMCc01VfTjJJ4FrklwG3ANc0mMPkqRZegv+qvoccNYcyx8A1vV1v5K69/IbvtFJnbdefFondXR4PHNXkgbG4JekgTH4JWlgDH5JGhiDX5IGxuCXpIEx+CVpYAx+SRoYg1+SBsbgl6SBMfglaWAMfkkamD5H55TG4hk3/Gkndf724j/qpI50pHOPX5IGxuCXpIEx+CVpYAx+SRqYPr9z97Qkf5fkriR3JnlFu3xFkq1JdrbT5X31IEnaX597/A8C/6WqHgs8CXhJkjOATcC2qloLbGvnJUlj0lvwV9Wuqrq9vf494C7gFGA9sKVdbQtwUV89SJL2N5Zj/EnW0Hzx+q3AqqraBc2LA7Bynm02JplKMjU9PT2ONiVpEHoP/iQPA64DXllV3x11u6raXFWTVTU5MTHRX4OSNDC9nrmb5Gia0L+qqq5vF+9OsrqqdiVZDezpswdpSC6+7u87qXPDs3+9kzo6MvX5qZ4A7wLuqqq/mHHTTcCG9voG4Ma+epAk7a/PPf5zgN8BPp9ke7vsD4HLgWuSXAbcA1zSYw+SpFl6C/6q+nsg89y8biE1p9/x/oU3NMPEf760kzqStBR55q4kDYzBL0kDY/BL0sAY/JI0MAa/JA2MwS9JA+N37mofb73qNzup8/IXfLSTOpK65x6/JA2MwS9JA+OhntZ9b3/VYdc4+SV/cfCVBuyFN5zfSZ0rL/5IJ3WkI83ut97SSZ1VL3/aAW93j1+SBsbgl6SBMfglaWAMfkkaGINfkgbG4JekgenzqxffnWRPkh0zlq1IsjXJzna6vK/7lyTNrc89/vcAsz+4vQnYVlVrgW3tvCRpjHoL/qr6OPDtWYvXA1va61uAi/q6f0nS3MZ9jH9VVe0CaKcr51sxycYkU0mmpqenx9agJP2yO2Lf3K2qzVU1WVWTExMTi92OJP3SGHfw706yGqCd7hnz/UvS4I17kLabgA3A5e30xjHf/y+Na6/sZsCz57zQAc+koenz45xXA58ETk9yb5LLaAL/vCQ7gfPaeUnSGPW2x19Vz5/npnV93aekpef6a+/vpM6znnNSJ3WG4Ih9c1eS1A+DX5IGxm/gkubxzOve2Umd//XsF3VSR+qKe/ySNDDu8ffsk5sv6KTOkzd+uJM60lB89p3dnCZ01ovmHWBgyXKPX5IGxuCXpIEx+CVpYAx+SRoYg1+SBsbgl6SBMfglaWAMfkkaGINfkgbG4JekgTH4JWlgDH5JGphFCf4k5yf5UpIvJ9m0GD1I0lCNPfiTHAW8Hfgt4Azg+UnOGHcfkjRUi7HH/0Tgy1X11ar6CfBBYP0i9CFJg5SqGu8dJs8Bzq+qF7XzvwP8WlW9dNZ6G4GN7ezpwJdGvIuTgG6+vXk8dfusvdTq9ll7qdXts/ZSq9tn7aVW91Br/0pVTcxeuBhfxJI5lu336lNVm4HNh1w8maqqyYU0thh1+6y91Or2WXup1e2z9lKr22ftpVa3q9qLcajnXuC0GfOnAvctQh+SNEiLEfyfAdYmeVSSY4DnATctQh+SNEhjP9RTVQ8meSnwUeAo4N1VdWeHd3HIh4cWuW6ftZda3T5rL7W6fdZeanX7rL3U6nZSe+xv7kqSFpdn7krSwBj8kjQwSzb4DzbsQxpvbW//XJKzR6z77iR7kuyY5/aF1j0tyd8luSvJnUle0UXtJMcm+XSSO9q6b+iq53bbo5J8NsmHO657d5LPJ9meZKqr2klOTHJtki+2j/WTD7duktPbPvdevpvklR31+/vt721HkquTHNtF3XbbV7R175zd76HUnus5kWRFkq1JdrbT5fNse7Dn6Vy1L2l7/nmSeT+2eKDa89R9U/t38bkkNyQ5saO6f9LW3J7k5iQnd/VYzLjt1UkqyUkLqb2fqlpyF5o3hb8CPBo4BrgDOGPWOs8A/jfNeQNPAm4dsfZTgbOBHfPcvtC6q4Gz2+snAP/YRc/tug9rrx8N3Ao8qYue221fBXwA+HBXj0W77d3ASQe4faGP8xbgRe31Y4ATu+p5xt/et2hOjDnc390pwNeAh7bz1wD/saPH4fHADuA4mg9x/B9g7UJqz/WcAP4c2NRe3wT82TyP1cGep3PVfizNSZu3AJMH+D3MW3ueur8BLGuv/9lCep6n7sNnXH858JddPRbt8tNoPgzzdeZ4zoxSe/Zlqe7xjzLsw3rgvdX4FHBiktUHK1xVHwe+fYBVFlp3V1Xd3l7/HnAXzRP/sGq3636/nT26vcx+x35BPSc5FXgm8M55VllQ3REdcu0kD6d58rwLoKp+UlXf6bjndcBXqurrHdVdBjw0yTKakJ59TstC6z4W+FRV/bCqHgQ+Bly8kNrzPCfW07zI0k4vmqOHgz5P56pdVXdV1cHO1D9g7Xnq3tw+FgCfojmHqIu6350xezxznJB6sLrz1W79T+AP5qk7Uu3ZlmrwnwJ8Y8b8vewfoqOs09d9H1CSNcBZNHvnh107zeGY7cAeYGtVdVIXeDPNH9zP57n9cB6LAm5Oclua4Tm6qP1oYBq4Ms3hqXcmOb7DnqE57+TqLvqtqm8CVwD3ALuAf66qmzvqdwfw1CSPSHIczd79abPWOZzHYlVV7Wp/jl3AyjnW6es52EXt36X5b6eTuknemOQbwAuA13VY90Lgm1V1xwFWO+TaSzX4Rxn2YaShIXq67/k3Th4GXAe8ctaewoJrV9XPqupMmj2YJyZ5/OHWTXIBsKeqbjvQaodad4ZzqupsmlFaX5LkqR3UXkbzr/I7quos4Ac0hyEOt26zYXPC4YXAX89186HWbY+LrwceBZwMHJ/k0sOtC81eM83hjK3AR2j+/X9w1mp9PUfGUf9wfo+vpXksruqqblW9tqpOa2u+dI5VFvL3cRzwWuZ+ITms2ks1+EcZ9qGvoSEWXDfJ0TShf1VVXd9lbYD2sMYtwPkd1D0HuDDJ3TT/Op6b5P1d9VtV97XTPcANNP+uHm7te4F7Z/zHcy3NC0EnPdO8SN1eVbvnue9Drft04GtVNV1VPwWuB57SVb9V9a6qOruqnkpzCGFnV7WB3XsPC7XTPXOs0+fwLAuqnWQDcAHwgmoPkHdRd4YPAM/uqO5jaHYK7mifh6cCtyd55GHXPtAbAEfqhWbP7qvtg7L3zYzHzVrnmez7xtWnD6H+GuZ/c3dBddv13wu8+QDrHHJtYIL2DUzgocAngAu6eiza7Z/G3G/uLvSxOB44Ycb1f6AZsbWL2p8ATm+vvx54U4d/Fx8EXtjh7+7XgDtpju2H5lj5yzrsd2U7/VfAF4HlC609+zkBvIl939z98zm2OejzdK7aM5bfwvxv7o6SAbN7Ph/4AjBxgJ9zIXXXzrj+MuDarh+L9ra7mfvN3ZFq77PNqH9ER9qF5pjlP9K8m/3adtmLgRe310PzhS9fAT4/3x/QHHWvpjne+lOaV9LLOqr76zT/fn0O2N5ennG4tYFfBT7b1t0BvK6rx2LGfTyNNvg7eiwe3f5x3kETfF3+/s4EptrH42+A5R3VPQ54APiXM5Z1UfcNNKG8A3gf8C+6+t3RvAh+oX2c1y20Z+Z+TjwC2EbzX8Q2YEW77snA3x7oeTpC7Yvb6z8GdgMfPdTa89T9Ms2x8O3t5S87qntd+/v7HPAh4JSuHotZt99NG/yHWnv2xSEbJGlgluoxfknSAhn8kjQwBr8kDYzBL0kDY/BL0sAY/NJBJHl9klcvdh9SVwx+SRoYg1+aJcl/aMdXvyPJ+2bd9ntJPtPedl07nsreMeR3tMs/3i57XJrvStje1lu7GD+PNJsncEkzJHkczZg551TV/UlW0Iyx/v2quiLJI6rqgXbdPwV2V9XbknyeZtiJbyY5saq+k+RtNEMjX9UO8HZUVf1osX42aS/3+KV9nUsz1sr9AFU1e3z0xyf5RBv0LwAe1y7/f8B7kvwezRdjAHwS+MMkr6H54hZDX0cEg1/aVzjwkLbvAV5aVf+WZpydYwGq6sXAH9GMkri9/c/gAzTDOP8I+GiSc/tsXBqVwS/taxvw3CSPgOa7ZWfdfgKwqx1i+wV7FyZ5TFXdWlWvA+4HTkvyaOCrVfVW4CaaAfWkRbdssRuQjiRVdWeSNwIfS/IzmpFP756xyn+j+ea0r9OMaHlCu/xN7Zu3oXnxuINmuOJLk/yU5nt6//tYfgjpIHxzV5IGxkM9kjQwBr8kDYzBL0kDY/BL0sAY/JI0MAa/JA2MwS9JA/P/ATaBEAaRHPzPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(temp['class'])\n",
    "plt.show()\n",
    "sns.countplot(Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the training data is well balanced now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare our Multi-class classification error metric function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "\n",
    "def error_metric(y_true,y_preds):\n",
    "    print (classification_report(y_true, y_preds))\n",
    "    print (confusion_matrix(y_true,y_preds))\n",
    "    print ('accuracy score: ',np.round(accuracy_score(y_true, y_preds)*100,2),'%') #check accuracy of model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.80      0.85        25\n",
      "         1.0       0.40      0.07      0.12        29\n",
      "         2.0       0.52      1.00      0.69        22\n",
      "         3.0       0.86      0.86      0.86        22\n",
      "         4.0       0.54      0.86      0.67        22\n",
      "         5.0       0.89      1.00      0.94        24\n",
      "         6.0       0.30      0.39      0.34        18\n",
      "         7.0       0.55      0.64      0.59        25\n",
      "         8.0       0.59      0.50      0.54        26\n",
      "         9.0       0.64      0.62      0.63        26\n",
      "        10.0       0.29      0.23      0.26        22\n",
      "        11.0       0.85      1.00      0.92        22\n",
      "        12.0       0.72      0.67      0.69        27\n",
      "        13.0       0.26      0.16      0.20        31\n",
      "        14.0       0.69      0.75      0.72        24\n",
      "\n",
      "    accuracy                           0.62       365\n",
      "   macro avg       0.60      0.64      0.60       365\n",
      "weighted avg       0.60      0.62      0.59       365\n",
      "\n",
      "[[20  0  0  0  0  0  0  0  0  0  0  0  0  3  2]\n",
      " [ 0  2  6  0  7  0  1  0  0  0  5  0  1  7  0]\n",
      " [ 0  0 22  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 19  0  0  0  0  3  0  0  0  0  0  0]\n",
      " [ 0  0  1  0 19  0  0  1  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 24  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  1  0  0  0  7  2  0  0  1  3  1  1  1]\n",
      " [ 0  0  3  0  0  0  4 16  0  0  0  0  0  0  2]\n",
      " [ 1  0  0  3  1  0  1  1 13  1  1  0  0  2  2]\n",
      " [ 0  0  5  0  1  0  0  3  0 16  0  0  0  1  0]\n",
      " [ 0  1  2  0  6  0  3  2  1  0  5  0  1  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 22  0  0  0]\n",
      " [ 0  0  0  0  0  3  0  2  0  2  2  0 18  0  0]\n",
      " [ 1  1  2  0  1  0  4  2  3  5  3  0  4  5  0]\n",
      " [ 0  0  0  0  0  0  3  0  2  0  0  1  0  0 18]]\n",
      "accuracy score:  61.92 %\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR_model = LogisticRegression().fit(X,Y) \n",
    "LR_preds = LR_model.predict(X_test)\n",
    "print (error_metric(y_test,LR_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.88      0.90        25\n",
      "         1.0       0.54      0.48      0.51        29\n",
      "         2.0       0.68      0.86      0.76        22\n",
      "         3.0       0.82      0.82      0.82        22\n",
      "         4.0       0.63      0.77      0.69        22\n",
      "         5.0       0.89      1.00      0.94        24\n",
      "         6.0       0.54      0.72      0.62        18\n",
      "         7.0       0.67      0.80      0.73        25\n",
      "         8.0       0.54      0.54      0.54        26\n",
      "         9.0       0.67      0.69      0.68        26\n",
      "        10.0       0.38      0.36      0.37        22\n",
      "        11.0       0.94      0.77      0.85        22\n",
      "        12.0       0.81      0.78      0.79        27\n",
      "        13.0       0.69      0.29      0.41        31\n",
      "        14.0       0.77      0.83      0.80        24\n",
      "\n",
      "    accuracy                           0.70       365\n",
      "   macro avg       0.70      0.71      0.69       365\n",
      "weighted avg       0.70      0.70      0.69       365\n",
      "\n",
      "[[22  0  0  0  0  0  0  0  1  0  1  0  0  0  1]\n",
      " [ 0 14  4  0  3  0  0  1  1  0  5  0  1  0  0]\n",
      " [ 0  0 19  0  0  0  1  0  0  1  1  0  0  0  0]\n",
      " [ 0  0  0 18  1  1  0  0  2  0  0  0  0  0  0]\n",
      " [ 0  3  0  0 17  0  0  0  1  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 24  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0 13  1  1  0  0  1  1  0  0]\n",
      " [ 0  0  0  0  1  0  2 20  0  1  0  0  0  0  1]\n",
      " [ 1  1  0  1  0  2  2  1 14  0  0  0  0  1  3]\n",
      " [ 0  1  4  0  0  0  0  0  1 18  2  0  0  0  0]\n",
      " [ 0  3  1  0  4  0  0  1  0  2  8  0  0  3  0]\n",
      " [ 0  0  0  0  0  0  4  0  0  0  1 17  0  0  0]\n",
      " [ 0  0  0  3  0  0  0  2  0  0  1  0 21  0  0]\n",
      " [ 1  3  0  0  1  0  0  3  4  4  2  0  3  9  1]\n",
      " [ 0  0  0  0  0  0  2  1  1  0  0  0  0  0 20]]\n",
      "accuracy score:  69.59 %\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT_model = DecisionTreeClassifier(criterion='entropy').fit(X,Y)\n",
    "DT_preds = DT_model.predict(X_test)\n",
    "print(error_metric(y_test,DT_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.88      0.90        25\n",
      "         1.0       0.65      0.52      0.58        29\n",
      "         2.0       0.65      0.91      0.75        22\n",
      "         3.0       1.00      0.95      0.98        22\n",
      "         4.0       0.72      0.82      0.77        22\n",
      "         5.0       0.89      1.00      0.94        24\n",
      "         6.0       0.54      0.72      0.62        18\n",
      "         7.0       0.75      0.84      0.79        25\n",
      "         8.0       0.58      0.54      0.56        26\n",
      "         9.0       0.73      0.62      0.67        26\n",
      "        10.0       0.52      0.68      0.59        22\n",
      "        11.0       0.89      0.77      0.83        22\n",
      "        12.0       0.79      0.85      0.82        27\n",
      "        13.0       0.86      0.39      0.53        31\n",
      "        14.0       0.80      0.83      0.82        24\n",
      "\n",
      "    accuracy                           0.74       365\n",
      "   macro avg       0.75      0.75      0.74       365\n",
      "weighted avg       0.76      0.74      0.74       365\n",
      "\n",
      "[[22  0  0  0  0  0  0  0  1  0  1  0  0  0  1]\n",
      " [ 0 15  3  0  3  0  0  0  0  2  3  0  3  0  0]\n",
      " [ 0  0 20  0  0  0  0  0  0  0  2  0  0  0  0]\n",
      " [ 0  0  0 21  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  1  0 18  0  0  0  1  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 24  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  1  0  0  0 13  2  1  0  0  0  0  0  0]\n",
      " [ 0  0  2  0  1  0  0 21  0  0  0  0  0  0  1]\n",
      " [ 1  0  0  0  0  2  3  1 14  0  0  1  0  2  2]\n",
      " [ 0  1  4  0  0  0  0  0  1 16  4  0  0  0  0]\n",
      " [ 0  3  0  0  2  0  0  2  0  0 15  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  4  0  0  0  1 17  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  3  0  0  0 23  0  0]\n",
      " [ 1  2  0  0  1  0  2  1  1  3  3  1  3 12  1]\n",
      " [ 0  0  0  0  0  0  2  0  2  0  0  0  0  0 20]]\n",
      "accuracy score:  74.25 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_model = RandomForestClassifier(n_estimators=100).fit(X,Y)\n",
    "RF_preds = RF_model.predict(X_test)\n",
    "error_metric(y_test,RF_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.84      0.86        25\n",
      "         1.0       0.20      0.03      0.06        29\n",
      "         2.0       0.55      1.00      0.71        22\n",
      "         3.0       0.72      0.82      0.77        22\n",
      "         4.0       0.51      0.91      0.66        22\n",
      "         5.0       0.83      1.00      0.91        24\n",
      "         6.0       0.30      0.44      0.36        18\n",
      "         7.0       0.43      0.36      0.39        25\n",
      "         8.0       0.60      0.35      0.44        26\n",
      "         9.0       0.64      0.69      0.67        26\n",
      "        10.0       0.35      0.36      0.36        22\n",
      "        11.0       0.70      0.73      0.71        22\n",
      "        12.0       0.72      0.67      0.69        27\n",
      "        13.0       0.31      0.16      0.21        31\n",
      "        14.0       0.72      0.75      0.73        24\n",
      "\n",
      "    accuracy                           0.59       365\n",
      "   macro avg       0.56      0.61      0.57       365\n",
      "weighted avg       0.56      0.59      0.56       365\n",
      "\n",
      "[[21  0  0  0  0  0  0  0  0  0  0  0  0  2  2]\n",
      " [ 0  1  5  0  8  0  0  0  0  2  6  0  0  6  1]\n",
      " [ 0  0 22  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 18  0  0  0  0  3  0  0  1  0  0  0]\n",
      " [ 0  0  1  0 20  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 24  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  1  0  8  2  0  0  1  0  1  2  2]\n",
      " [ 0  0  4  0  2  0  7  9  1  0  0  0  1  0  1]\n",
      " [ 1  0  0  6  0  3  3  2  9  0  1  0  0  0  1]\n",
      " [ 0  0  3  0  1  0  0  3  0 18  0  0  0  1  0]\n",
      " [ 0  0  3  0  6  0  3  1  0  0  8  0  1  0  0]\n",
      " [ 0  4  0  0  0  0  0  0  0  0  1 16  1  0  0]\n",
      " [ 0  0  0  0  0  2  0  2  0  2  2  1 18  0  0]\n",
      " [ 1  0  1  0  1  0  5  2  0  5  4  4  3  5  0]\n",
      " [ 1  0  0  1  0  0  1  0  2  0  0  1  0  0 18]]\n",
      "accuracy score:  58.9 %\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB_model = MultinomialNB().fit(X,Y)\n",
    "NB_preds = NB_model.predict(X_test)\n",
    "print (error_metric(y_test,NB_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.88      0.90        25\n",
      "         1.0       0.72      0.62      0.67        29\n",
      "         2.0       0.67      0.82      0.73        22\n",
      "         3.0       1.00      0.95      0.98        22\n",
      "         4.0       0.62      0.68      0.65        22\n",
      "         5.0       0.86      1.00      0.92        24\n",
      "         6.0       0.65      0.72      0.68        18\n",
      "         7.0       0.60      0.84      0.70        25\n",
      "         8.0       0.64      0.35      0.45        26\n",
      "         9.0       0.70      0.62      0.65        26\n",
      "        10.0       0.38      0.59      0.46        22\n",
      "        11.0       0.90      0.82      0.86        22\n",
      "        12.0       0.79      0.85      0.82        27\n",
      "        13.0       0.60      0.19      0.29        31\n",
      "        14.0       0.71      0.92      0.80        24\n",
      "\n",
      "    accuracy                           0.71       365\n",
      "   macro avg       0.72      0.72      0.70       365\n",
      "weighted avg       0.72      0.71      0.70       365\n",
      "\n",
      "[[22  0  0  0  0  0  0  0  2  0  1  0  0  0  0]\n",
      " [ 0 18  0  0  2  0  0  2  0  1  5  0  1  0  0]\n",
      " [ 0  0 18  0  0  0  0  0  0  0  4  0  0  0  0]\n",
      " [ 0  0  0 21  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  4  0  0 15  0  0  0  0  1  2  0  0  0  0]\n",
      " [ 0  0  0  0  0 24  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  1  0 13  1  0  0  0  1  0  0  1]\n",
      " [ 0  0  4  0  0  0  0 21  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  3  2  0  2  9  0  0  0  1  3  5]\n",
      " [ 0  0  4  0  1  0  0  0  0 16  4  0  1  0  0]\n",
      " [ 0  1  0  0  2  0  1  4  0  0 13  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  4  0  0  0  0 18  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  2  0  0  1  0 23  0  0]\n",
      " [ 1  2  0  0  0  0  2  3  1  5  4  1  3  6  3]\n",
      " [ 0  0  0  0  0  0  0  0  2  0  0  0  0  0 22]]\n",
      "accuracy score:  70.96 %\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "K_model = KNeighborsClassifier(n_neighbors=5).fit(X,Y)\n",
    "K_preds = K_model.predict(X_test)\n",
    "print (error_metric(y_test,K_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADABoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.76      0.83        25\n",
      "         1.0       0.00      0.00      0.00        29\n",
      "         2.0       0.15      1.00      0.27        22\n",
      "         3.0       0.25      0.50      0.33        22\n",
      "         4.0       0.00      0.00      0.00        22\n",
      "         5.0       0.00      0.00      0.00        24\n",
      "         6.0       0.11      0.06      0.07        18\n",
      "         7.0       0.00      0.00      0.00        25\n",
      "         8.0       0.60      0.23      0.33        26\n",
      "         9.0       0.00      0.00      0.00        26\n",
      "        10.0       0.00      0.00      0.00        22\n",
      "        11.0       0.17      1.00      0.29        22\n",
      "        12.0       0.00      0.00      0.00        27\n",
      "        13.0       0.17      0.03      0.05        31\n",
      "        14.0       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.22       365\n",
      "   macro avg       0.16      0.24      0.14       365\n",
      "weighted avg       0.16      0.22      0.14       365\n",
      "\n",
      "[[19  0  4  0  0  0  0  0  0  0  0  0  0  2  0]\n",
      " [ 0  0 16  0  0  0  0  0  0  0  0 13  0  0  0]\n",
      " [ 0  0 22  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 11  0  0  0  0  2  0  0  9  0  0  0]\n",
      " [ 0  0 22  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 23  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  5  0  0  0  1  0  0  0  0 11  0  1  0]\n",
      " [ 0  0  9  1  0  0  3  0  0  0  0 12  0  0  0]\n",
      " [ 1  0  2  9  0  0  0  0  6  0  0  7  0  1  0]\n",
      " [ 0  0 26  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 10  0  0  0  0  0  0  0  0 12  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 22  0  0  0]\n",
      " [ 0  0  2  0  0  0  3  0  0  0  0 22  0  0  0]\n",
      " [ 1  0 11  0  0  0  0  0  0  0  0 18  0  1  0]\n",
      " [ 0  0 15  0  0  0  2  0  1  0  0  5  0  1  0]]\n",
      "accuracy score:  22.47 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_classifier=AdaBoostClassifier().fit(X,Y)\n",
    "ADA_preds = ada_classifier.predict(X_test)\n",
    "error_metric(y_test,ADA_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.84      0.87        25\n",
      "         1.0       0.65      0.52      0.58        29\n",
      "         2.0       0.67      0.91      0.77        22\n",
      "         3.0       1.00      0.95      0.98        22\n",
      "         4.0       0.68      0.68      0.68        22\n",
      "         5.0       0.96      1.00      0.98        24\n",
      "         6.0       0.62      0.72      0.67        18\n",
      "         7.0       0.74      0.92      0.82        25\n",
      "         8.0       0.64      0.54      0.58        26\n",
      "         9.0       0.67      0.69      0.68        26\n",
      "        10.0       0.42      0.50      0.46        22\n",
      "        11.0       0.78      0.82      0.80        22\n",
      "        12.0       0.76      0.93      0.83        27\n",
      "        13.0       0.67      0.32      0.43        31\n",
      "        14.0       0.87      0.83      0.85        24\n",
      "\n",
      "    accuracy                           0.73       365\n",
      "   macro avg       0.74      0.75      0.73       365\n",
      "weighted avg       0.74      0.73      0.73       365\n",
      "\n",
      "[[21  0  0  0  0  0  0  0  2  0  0  0  0  2  0]\n",
      " [ 0 15  2  0  3  0  0  0  1  2  3  0  3  0  0]\n",
      " [ 0  0 20  0  0  0  0  0  0  0  2  0  0  0  0]\n",
      " [ 0  0  0 21  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0 15  0  1  0  0  2  2  0  0  0  0]\n",
      " [ 0  0  0  0  0 24  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0 13  0  1  0  0  1  1  1  0]\n",
      " [ 0  0  2  0  0  0  0 23  0  0  0  0  0  0  0]\n",
      " [ 1  1  0  0  1  0  2  1 14  0  0  2  0  2  2]\n",
      " [ 0  0  4  0  0  0  0  0  1 18  3  0  0  0  0]\n",
      " [ 0  4  0  0  2  0  0  1  1  1 11  1  1  0  0]\n",
      " [ 0  0  0  0  0  0  3  0  0  0  1 18  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  1  0 25  0  0]\n",
      " [ 1  1  1  0  1  0  1  4  1  4  3  0  3 10  1]\n",
      " [ 0  0  0  0  0  0  1  1  1  0  0  1  0  0 20]]\n",
      "accuracy score:  73.42 %\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "XG_model = XGBClassifier(objective='multi:softprob').fit(pd.DataFrame(data=X,columns = X_test.columns),Y)\n",
    "XG_preds = XG_model.predict(X_test)\n",
    "error_metric(y_test,XG_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.84      0.87        25\n",
      "         1.0       1.00      0.52      0.68        29\n",
      "         2.0       0.61      1.00      0.76        22\n",
      "         3.0       1.00      1.00      1.00        22\n",
      "         4.0       0.68      0.95      0.79        22\n",
      "         5.0       0.89      1.00      0.94        24\n",
      "         6.0       0.52      0.61      0.56        18\n",
      "         7.0       0.59      0.88      0.71        25\n",
      "         8.0       0.82      0.54      0.65        26\n",
      "         9.0       0.61      0.54      0.57        26\n",
      "        10.0       0.48      0.64      0.55        22\n",
      "        11.0       1.00      0.82      0.90        22\n",
      "        12.0       0.79      0.81      0.80        27\n",
      "        13.0       0.75      0.29      0.42        31\n",
      "        14.0       0.77      0.83      0.80        24\n",
      "\n",
      "    accuracy                           0.74       365\n",
      "   macro avg       0.76      0.75      0.73       365\n",
      "weighted avg       0.77      0.74      0.73       365\n",
      "\n",
      "[[21  0  3  0  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0 15  1  0  5  0  0  0  0  2  4  0  2  0  0]\n",
      " [ 0  0 22  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 22  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 21  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 24  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0 11  3  1  0  1  0  0  0  1]\n",
      " [ 0  0  3  0  0  0  0 22  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  2  2  1 14  0  1  0  0  2  3]\n",
      " [ 0  0  4  0  1  0  0  0  0 14  6  0  1  0  0]\n",
      " [ 0  0  1  0  3  0  0  4  0  0 14  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  4  0  0  0  0 18  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  4  0  0  0  0 22  0  0]\n",
      " [ 1  0  1  0  1  0  2  3  0  6  3  0  3  9  2]\n",
      " [ 0  0  0  0  0  0  2  0  2  0  0  0  0  0 20]]\n",
      "accuracy score:  73.7 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "SV_model = SVC(C=1.0).fit(X,Y)\n",
    "SV_preds = SV_model.predict(X_test)\n",
    "error_metric(y_test,SV_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to one -hot-encode the target variable to use it for Neural-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1700, 15)\n",
      "(365, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_0.0</th>\n",
       "      <th>class_1.0</th>\n",
       "      <th>class_2.0</th>\n",
       "      <th>class_3.0</th>\n",
       "      <th>class_4.0</th>\n",
       "      <th>class_5.0</th>\n",
       "      <th>class_6.0</th>\n",
       "      <th>class_7.0</th>\n",
       "      <th>class_8.0</th>\n",
       "      <th>class_9.0</th>\n",
       "      <th>class_10.0</th>\n",
       "      <th>class_11.0</th>\n",
       "      <th>class_12.0</th>\n",
       "      <th>class_13.0</th>\n",
       "      <th>class_14.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_0.0  class_1.0  class_2.0  class_3.0  class_4.0  class_5.0  \\\n",
       "0          0          0          0          0          0          0   \n",
       "1          0          0          0          0          0          0   \n",
       "\n",
       "   class_6.0  class_7.0  class_8.0  class_9.0  class_10.0  class_11.0  \\\n",
       "0          0          0          1          0           0           0   \n",
       "1          0          1          0          0           0           0   \n",
       "\n",
       "   class_12.0  class_13.0  class_14.0  \n",
       "0           0           0           0  \n",
       "1           0           0           0  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.get_dummies(Y,prefix='class')\n",
    "test_targets = pd.get_dummies(y_test, prefix='class')\n",
    "print (target.shape)\n",
    "print (test_targets.shape)\n",
    "target.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(32, activation='sigmoid', input_shape=(X.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='tanh'))\n",
    "    model.add(layers.Dense(len(set(y_test)), activation='softmax')) # because of multi-class labels\n",
    "    # defining the optimizer and loss and accuracy parameters\n",
    "    model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1190, 16) (1190, 15)\n",
      "(510, 16) (510, 15)\n",
      "Epoch 1/500\n",
      "149/149 [==============================] - 1s 6ms/step - loss: 2.6618 - accuracy: 0.1101 - val_loss: 2.5706 - val_accuracy: 0.2196\n",
      "Epoch 2/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 2.4610 - accuracy: 0.2588 - val_loss: 2.3077 - val_accuracy: 0.3294\n",
      "Epoch 3/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 2.1773 - accuracy: 0.3832 - val_loss: 2.0488 - val_accuracy: 0.3471\n",
      "Epoch 4/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 1.9348 - accuracy: 0.4429 - val_loss: 1.8132 - val_accuracy: 0.4569\n",
      "Epoch 5/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 1.7598 - accuracy: 0.4950 - val_loss: 1.6652 - val_accuracy: 0.5020\n",
      "Epoch 6/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 1.6373 - accuracy: 0.5277 - val_loss: 1.5248 - val_accuracy: 0.5569\n",
      "Epoch 7/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 1.5372 - accuracy: 0.5555 - val_loss: 1.4579 - val_accuracy: 0.5529\n",
      "Epoch 8/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 1.4603 - accuracy: 0.5874 - val_loss: 1.4001 - val_accuracy: 0.5627\n",
      "Epoch 9/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 1.3987 - accuracy: 0.6025 - val_loss: 1.3381 - val_accuracy: 0.5784\n",
      "Epoch 10/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 1.3436 - accuracy: 0.6067 - val_loss: 1.3022 - val_accuracy: 0.5843\n",
      "Epoch 11/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 1.2986 - accuracy: 0.6227 - val_loss: 1.2794 - val_accuracy: 0.5980\n",
      "Epoch 12/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 1.2583 - accuracy: 0.6176 - val_loss: 1.2247 - val_accuracy: 0.6157\n",
      "Epoch 13/500\n",
      "149/149 [==============================] - ETA: 0s - loss: 1.2357 - accuracy: 0.63 - 1s 4ms/step - loss: 1.2281 - accuracy: 0.6403 - val_loss: 1.2131 - val_accuracy: 0.6176\n",
      "Epoch 14/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 1.2005 - accuracy: 0.6403 - val_loss: 1.1694 - val_accuracy: 0.6275\n",
      "Epoch 15/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 1.1790 - accuracy: 0.6403 - val_loss: 1.1609 - val_accuracy: 0.6275\n",
      "Epoch 16/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 1.1529 - accuracy: 0.6563 - val_loss: 1.1487 - val_accuracy: 0.6275\n",
      "Epoch 17/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 1.1435 - accuracy: 0.6479 - val_loss: 1.1075 - val_accuracy: 0.6588\n",
      "Epoch 18/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 1.1223 - accuracy: 0.6555 - val_loss: 1.1357 - val_accuracy: 0.6157\n",
      "Epoch 19/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 1.1092 - accuracy: 0.6655 - val_loss: 1.0963 - val_accuracy: 0.6569\n",
      "Epoch 20/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 1.0927 - accuracy: 0.6655 - val_loss: 1.0965 - val_accuracy: 0.6333\n",
      "Epoch 21/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 1.0819 - accuracy: 0.6723 - val_loss: 1.0851 - val_accuracy: 0.6588\n",
      "Epoch 22/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 1.0659 - accuracy: 0.6773 - val_loss: 1.0659 - val_accuracy: 0.6451\n",
      "Epoch 23/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 1.0565 - accuracy: 0.6790 - val_loss: 1.0521 - val_accuracy: 0.6569\n",
      "Epoch 24/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 1.0485 - accuracy: 0.6882 - val_loss: 1.0392 - val_accuracy: 0.6608\n",
      "Epoch 25/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 1.0360 - accuracy: 0.6924 - val_loss: 1.0187 - val_accuracy: 0.6725\n",
      "Epoch 26/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 1.0272 - accuracy: 0.6849 - val_loss: 1.0247 - val_accuracy: 0.6804\n",
      "Epoch 27/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 1.0168 - accuracy: 0.6924 - val_loss: 1.0141 - val_accuracy: 0.6765\n",
      "Epoch 28/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 1.0007 - accuracy: 0.6908 - val_loss: 1.0065 - val_accuracy: 0.6765\n",
      "Epoch 29/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 1.0013 - accuracy: 0.6933 - val_loss: 0.9880 - val_accuracy: 0.6765\n",
      "Epoch 30/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.9911 - accuracy: 0.7017 - val_loss: 0.9997 - val_accuracy: 0.6863\n",
      "Epoch 31/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.9841 - accuracy: 0.6874 - val_loss: 0.9899 - val_accuracy: 0.6804\n",
      "Epoch 32/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.9743 - accuracy: 0.6983 - val_loss: 0.9844 - val_accuracy: 0.6843\n",
      "Epoch 33/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.9726 - accuracy: 0.7000 - val_loss: 0.9775 - val_accuracy: 0.6824\n",
      "Epoch 34/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.9613 - accuracy: 0.7067 - val_loss: 0.9665 - val_accuracy: 0.6804\n",
      "Epoch 35/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.9535 - accuracy: 0.7034 - val_loss: 0.9682 - val_accuracy: 0.6784\n",
      "Epoch 36/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.9468 - accuracy: 0.7067 - val_loss: 0.9584 - val_accuracy: 0.6843\n",
      "Epoch 37/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.9422 - accuracy: 0.7059 - val_loss: 0.9600 - val_accuracy: 0.6745\n",
      "Epoch 38/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.9312 - accuracy: 0.7050 - val_loss: 0.9352 - val_accuracy: 0.6922\n",
      "Epoch 39/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.9281 - accuracy: 0.7092 - val_loss: 0.9386 - val_accuracy: 0.7059\n",
      "Epoch 40/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.9226 - accuracy: 0.7151 - val_loss: 0.9278 - val_accuracy: 0.7020\n",
      "Epoch 41/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.9178 - accuracy: 0.7126 - val_loss: 0.9318 - val_accuracy: 0.7000\n",
      "Epoch 42/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.9079 - accuracy: 0.7160 - val_loss: 0.9278 - val_accuracy: 0.6961\n",
      "Epoch 43/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.9033 - accuracy: 0.7109 - val_loss: 0.9339 - val_accuracy: 0.6882\n",
      "Epoch 44/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.8956 - accuracy: 0.7227 - val_loss: 0.9296 - val_accuracy: 0.6804\n",
      "Epoch 45/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.8887 - accuracy: 0.7168 - val_loss: 0.9220 - val_accuracy: 0.6980\n",
      "Epoch 46/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.8797 - accuracy: 0.7235 - val_loss: 0.9019 - val_accuracy: 0.7020\n",
      "Epoch 47/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.8768 - accuracy: 0.7244 - val_loss: 0.8973 - val_accuracy: 0.6961\n",
      "Epoch 48/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.8698 - accuracy: 0.7244 - val_loss: 0.8817 - val_accuracy: 0.7118\n",
      "Epoch 49/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.8671 - accuracy: 0.7227 - val_loss: 0.8878 - val_accuracy: 0.6980\n",
      "Epoch 50/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.8559 - accuracy: 0.7286 - val_loss: 0.9047 - val_accuracy: 0.6902\n",
      "Epoch 51/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.8532 - accuracy: 0.7353 - val_loss: 0.8926 - val_accuracy: 0.6980\n",
      "Epoch 52/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.8456 - accuracy: 0.7361 - val_loss: 0.8845 - val_accuracy: 0.7000\n",
      "Epoch 53/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.8425 - accuracy: 0.7412 - val_loss: 0.8802 - val_accuracy: 0.6980\n",
      "Epoch 54/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.8321 - accuracy: 0.7454 - val_loss: 0.8648 - val_accuracy: 0.7235\n",
      "Epoch 55/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.8333 - accuracy: 0.7294 - val_loss: 0.8645 - val_accuracy: 0.7235\n",
      "Epoch 56/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.8221 - accuracy: 0.7361 - val_loss: 0.8619 - val_accuracy: 0.7098\n",
      "Epoch 57/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 1s 4ms/step - loss: 0.8149 - accuracy: 0.7420 - val_loss: 0.8641 - val_accuracy: 0.7098\n",
      "Epoch 58/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.8093 - accuracy: 0.7420 - val_loss: 0.8471 - val_accuracy: 0.7118\n",
      "Epoch 59/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.8013 - accuracy: 0.7445 - val_loss: 0.8558 - val_accuracy: 0.7216\n",
      "Epoch 60/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.8011 - accuracy: 0.7504 - val_loss: 0.8483 - val_accuracy: 0.7235\n",
      "Epoch 61/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.7859 - accuracy: 0.7513 - val_loss: 0.8471 - val_accuracy: 0.7412\n",
      "Epoch 62/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.7846 - accuracy: 0.7580 - val_loss: 0.8431 - val_accuracy: 0.7294\n",
      "Epoch 63/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.7801 - accuracy: 0.7580 - val_loss: 0.8167 - val_accuracy: 0.7451\n",
      "Epoch 64/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.7738 - accuracy: 0.7546 - val_loss: 0.8225 - val_accuracy: 0.7255\n",
      "Epoch 65/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.7649 - accuracy: 0.7571 - val_loss: 0.8080 - val_accuracy: 0.7412\n",
      "Epoch 66/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.7594 - accuracy: 0.7613 - val_loss: 0.8193 - val_accuracy: 0.7235\n",
      "Epoch 67/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.7596 - accuracy: 0.7487 - val_loss: 0.7907 - val_accuracy: 0.7471\n",
      "Epoch 68/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.7515 - accuracy: 0.7697 - val_loss: 0.8022 - val_accuracy: 0.7412\n",
      "Epoch 69/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.7429 - accuracy: 0.7655 - val_loss: 0.7959 - val_accuracy: 0.7373\n",
      "Epoch 70/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.7425 - accuracy: 0.7706 - val_loss: 0.7839 - val_accuracy: 0.7431\n",
      "Epoch 71/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.7322 - accuracy: 0.7706 - val_loss: 0.7811 - val_accuracy: 0.7490\n",
      "Epoch 72/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.7242 - accuracy: 0.7689 - val_loss: 0.7813 - val_accuracy: 0.7412\n",
      "Epoch 73/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.7207 - accuracy: 0.7655 - val_loss: 0.7683 - val_accuracy: 0.7569\n",
      "Epoch 74/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.7188 - accuracy: 0.7807 - val_loss: 0.7770 - val_accuracy: 0.7451\n",
      "Epoch 75/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.7124 - accuracy: 0.7773 - val_loss: 0.7620 - val_accuracy: 0.7549\n",
      "Epoch 76/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.7108 - accuracy: 0.7714 - val_loss: 0.7581 - val_accuracy: 0.7471\n",
      "Epoch 77/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6995 - accuracy: 0.7807 - val_loss: 0.7448 - val_accuracy: 0.7588\n",
      "Epoch 78/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6955 - accuracy: 0.7815 - val_loss: 0.7572 - val_accuracy: 0.7569\n",
      "Epoch 79/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6915 - accuracy: 0.7756 - val_loss: 0.7365 - val_accuracy: 0.7569\n",
      "Epoch 80/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6826 - accuracy: 0.7807 - val_loss: 0.7506 - val_accuracy: 0.7569\n",
      "Epoch 81/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6817 - accuracy: 0.7815 - val_loss: 0.7534 - val_accuracy: 0.7529\n",
      "Epoch 82/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6742 - accuracy: 0.7849 - val_loss: 0.7414 - val_accuracy: 0.7627\n",
      "Epoch 83/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6707 - accuracy: 0.7748 - val_loss: 0.7416 - val_accuracy: 0.7490\n",
      "Epoch 84/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6634 - accuracy: 0.7908 - val_loss: 0.7231 - val_accuracy: 0.7549\n",
      "Epoch 85/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6632 - accuracy: 0.7882 - val_loss: 0.7197 - val_accuracy: 0.7647\n",
      "Epoch 86/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6571 - accuracy: 0.7815 - val_loss: 0.7100 - val_accuracy: 0.7706\n",
      "Epoch 87/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6526 - accuracy: 0.7924 - val_loss: 0.6966 - val_accuracy: 0.7725\n",
      "Epoch 88/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6469 - accuracy: 0.7983 - val_loss: 0.6925 - val_accuracy: 0.7627\n",
      "Epoch 89/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6430 - accuracy: 0.7983 - val_loss: 0.7000 - val_accuracy: 0.7725\n",
      "Epoch 90/500\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6369 - accuracy: 0.8067 - val_loss: 0.6925 - val_accuracy: 0.7725\n",
      "Epoch 91/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6355 - accuracy: 0.8042 - val_loss: 0.6906 - val_accuracy: 0.7725\n",
      "Epoch 92/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6345 - accuracy: 0.8008 - val_loss: 0.6848 - val_accuracy: 0.7824\n",
      "Epoch 93/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6234 - accuracy: 0.7966 - val_loss: 0.6984 - val_accuracy: 0.7706\n",
      "Epoch 94/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6190 - accuracy: 0.7958 - val_loss: 0.6919 - val_accuracy: 0.7627\n",
      "Epoch 95/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6103 - accuracy: 0.7975 - val_loss: 0.6934 - val_accuracy: 0.7804\n",
      "Epoch 96/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6147 - accuracy: 0.7966 - val_loss: 0.6841 - val_accuracy: 0.7804\n",
      "Epoch 97/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5981 - accuracy: 0.8025 - val_loss: 0.6912 - val_accuracy: 0.7843\n",
      "Epoch 98/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6040 - accuracy: 0.8076 - val_loss: 0.6763 - val_accuracy: 0.7824\n",
      "Epoch 99/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5972 - accuracy: 0.8042 - val_loss: 0.6632 - val_accuracy: 0.7824\n",
      "Epoch 100/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5961 - accuracy: 0.8118 - val_loss: 0.6607 - val_accuracy: 0.7961\n",
      "Epoch 101/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5848 - accuracy: 0.8076 - val_loss: 0.7027 - val_accuracy: 0.7706\n",
      "Epoch 102/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5785 - accuracy: 0.8185 - val_loss: 0.6667 - val_accuracy: 0.7784\n",
      "Epoch 103/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5803 - accuracy: 0.8118 - val_loss: 0.6558 - val_accuracy: 0.7902\n",
      "Epoch 104/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5768 - accuracy: 0.8143 - val_loss: 0.6525 - val_accuracy: 0.7882\n",
      "Epoch 105/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5727 - accuracy: 0.8034 - val_loss: 0.6384 - val_accuracy: 0.7941\n",
      "Epoch 106/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5665 - accuracy: 0.8101 - val_loss: 0.6476 - val_accuracy: 0.7686\n",
      "Epoch 107/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5652 - accuracy: 0.8126 - val_loss: 0.6342 - val_accuracy: 0.7902\n",
      "Epoch 108/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5645 - accuracy: 0.8109 - val_loss: 0.6284 - val_accuracy: 0.7902\n",
      "Epoch 109/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5585 - accuracy: 0.8126 - val_loss: 0.6617 - val_accuracy: 0.7784\n",
      "Epoch 110/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5529 - accuracy: 0.8185 - val_loss: 0.6749 - val_accuracy: 0.7941\n",
      "Epoch 111/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5472 - accuracy: 0.8210 - val_loss: 0.6393 - val_accuracy: 0.8000\n",
      "Epoch 112/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5460 - accuracy: 0.8227 - val_loss: 0.6342 - val_accuracy: 0.7902\n",
      "Epoch 113/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5429 - accuracy: 0.8176 - val_loss: 0.6158 - val_accuracy: 0.7804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5389 - accuracy: 0.8218 - val_loss: 0.6231 - val_accuracy: 0.7922\n",
      "Epoch 115/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5364 - accuracy: 0.8235 - val_loss: 0.6126 - val_accuracy: 0.7824\n",
      "Epoch 116/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5284 - accuracy: 0.8252 - val_loss: 0.6320 - val_accuracy: 0.7922\n",
      "Epoch 117/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5291 - accuracy: 0.8294 - val_loss: 0.5984 - val_accuracy: 0.8059\n",
      "Epoch 118/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5257 - accuracy: 0.8244 - val_loss: 0.6022 - val_accuracy: 0.7980\n",
      "Epoch 119/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5203 - accuracy: 0.8311 - val_loss: 0.6197 - val_accuracy: 0.7863\n",
      "Epoch 120/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5163 - accuracy: 0.8294 - val_loss: 0.5981 - val_accuracy: 0.8059\n",
      "Epoch 121/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5179 - accuracy: 0.8311 - val_loss: 0.6076 - val_accuracy: 0.7961\n",
      "Epoch 122/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5081 - accuracy: 0.8303 - val_loss: 0.6054 - val_accuracy: 0.7961\n",
      "Epoch 123/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5044 - accuracy: 0.8361 - val_loss: 0.6114 - val_accuracy: 0.8020\n",
      "Epoch 124/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5021 - accuracy: 0.8345 - val_loss: 0.5859 - val_accuracy: 0.8000\n",
      "Epoch 125/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5029 - accuracy: 0.8303 - val_loss: 0.6034 - val_accuracy: 0.7961\n",
      "Epoch 126/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4948 - accuracy: 0.8370 - val_loss: 0.5916 - val_accuracy: 0.7922\n",
      "Epoch 127/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4974 - accuracy: 0.8353 - val_loss: 0.5852 - val_accuracy: 0.8039\n",
      "Epoch 128/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4856 - accuracy: 0.8319 - val_loss: 0.5991 - val_accuracy: 0.7961\n",
      "Epoch 129/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4891 - accuracy: 0.8420 - val_loss: 0.6008 - val_accuracy: 0.7980\n",
      "Epoch 130/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4850 - accuracy: 0.8429 - val_loss: 0.5953 - val_accuracy: 0.8000\n",
      "Epoch 131/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4879 - accuracy: 0.8345 - val_loss: 0.5902 - val_accuracy: 0.8176\n",
      "Epoch 132/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4766 - accuracy: 0.8420 - val_loss: 0.5937 - val_accuracy: 0.7902\n",
      "Epoch 133/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4733 - accuracy: 0.8445 - val_loss: 0.5894 - val_accuracy: 0.7961\n",
      "Epoch 134/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4774 - accuracy: 0.8420 - val_loss: 0.5808 - val_accuracy: 0.7902\n",
      "Epoch 135/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4753 - accuracy: 0.8387 - val_loss: 0.5619 - val_accuracy: 0.8098\n",
      "Epoch 136/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4684 - accuracy: 0.8437 - val_loss: 0.5634 - val_accuracy: 0.8137\n",
      "Epoch 137/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4667 - accuracy: 0.8513 - val_loss: 0.5723 - val_accuracy: 0.8137\n",
      "Epoch 138/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4628 - accuracy: 0.8437 - val_loss: 0.5801 - val_accuracy: 0.7980\n",
      "Epoch 139/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4621 - accuracy: 0.8445 - val_loss: 0.5589 - val_accuracy: 0.8157\n",
      "Epoch 140/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4589 - accuracy: 0.8496 - val_loss: 0.5662 - val_accuracy: 0.8118\n",
      "Epoch 141/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4580 - accuracy: 0.8471 - val_loss: 0.5631 - val_accuracy: 0.8118\n",
      "Epoch 142/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4506 - accuracy: 0.8487 - val_loss: 0.5811 - val_accuracy: 0.8137\n",
      "Epoch 143/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4490 - accuracy: 0.8513 - val_loss: 0.5670 - val_accuracy: 0.7922\n",
      "Epoch 144/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4485 - accuracy: 0.8563 - val_loss: 0.5533 - val_accuracy: 0.8059\n",
      "Epoch 145/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4491 - accuracy: 0.8538 - val_loss: 0.5514 - val_accuracy: 0.8118\n",
      "Epoch 146/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4433 - accuracy: 0.8521 - val_loss: 0.5626 - val_accuracy: 0.7941\n",
      "Epoch 147/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4421 - accuracy: 0.8529 - val_loss: 0.5590 - val_accuracy: 0.8039\n",
      "Epoch 148/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4379 - accuracy: 0.8521 - val_loss: 0.5739 - val_accuracy: 0.8118\n",
      "Epoch 149/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4379 - accuracy: 0.8496 - val_loss: 0.5613 - val_accuracy: 0.8157\n",
      "Epoch 150/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4330 - accuracy: 0.8521 - val_loss: 0.5595 - val_accuracy: 0.8118\n",
      "Epoch 151/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4272 - accuracy: 0.8555 - val_loss: 0.5559 - val_accuracy: 0.8000\n",
      "Epoch 152/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4345 - accuracy: 0.8546 - val_loss: 0.5363 - val_accuracy: 0.8078\n",
      "Epoch 153/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4310 - accuracy: 0.8546 - val_loss: 0.5492 - val_accuracy: 0.8137\n",
      "Epoch 154/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4248 - accuracy: 0.8563 - val_loss: 0.5497 - val_accuracy: 0.8275\n",
      "Epoch 155/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4245 - accuracy: 0.8613 - val_loss: 0.5388 - val_accuracy: 0.8275\n",
      "Epoch 156/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4159 - accuracy: 0.8580 - val_loss: 0.5671 - val_accuracy: 0.8176\n",
      "Epoch 157/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4187 - accuracy: 0.8580 - val_loss: 0.5389 - val_accuracy: 0.8176\n",
      "Epoch 158/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4124 - accuracy: 0.8622 - val_loss: 0.5498 - val_accuracy: 0.8255\n",
      "Epoch 159/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4177 - accuracy: 0.8647 - val_loss: 0.5311 - val_accuracy: 0.8255\n",
      "Epoch 160/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4146 - accuracy: 0.8605 - val_loss: 0.5416 - val_accuracy: 0.8235\n",
      "Epoch 161/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4123 - accuracy: 0.8622 - val_loss: 0.5395 - val_accuracy: 0.8196\n",
      "Epoch 162/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4107 - accuracy: 0.8555 - val_loss: 0.5421 - val_accuracy: 0.8157\n",
      "Epoch 163/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4070 - accuracy: 0.8639 - val_loss: 0.5296 - val_accuracy: 0.8118\n",
      "Epoch 164/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4014 - accuracy: 0.8571 - val_loss: 0.5526 - val_accuracy: 0.8235\n",
      "Epoch 165/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4012 - accuracy: 0.8664 - val_loss: 0.5396 - val_accuracy: 0.8275\n",
      "Epoch 166/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3972 - accuracy: 0.8546 - val_loss: 0.5330 - val_accuracy: 0.8255\n",
      "Epoch 167/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3989 - accuracy: 0.8622 - val_loss: 0.5370 - val_accuracy: 0.8255\n",
      "Epoch 168/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3893 - accuracy: 0.8639 - val_loss: 0.5336 - val_accuracy: 0.8275\n",
      "Epoch 169/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4000 - accuracy: 0.8714 - val_loss: 0.5325 - val_accuracy: 0.8373\n",
      "Epoch 170/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3918 - accuracy: 0.8588 - val_loss: 0.5330 - val_accuracy: 0.8196\n",
      "Epoch 171/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3939 - accuracy: 0.8664 - val_loss: 0.5217 - val_accuracy: 0.8294\n",
      "Epoch 172/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3914 - accuracy: 0.8689 - val_loss: 0.5285 - val_accuracy: 0.8314\n",
      "Epoch 173/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3872 - accuracy: 0.8697 - val_loss: 0.5249 - val_accuracy: 0.8196\n",
      "Epoch 174/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3876 - accuracy: 0.8689 - val_loss: 0.5165 - val_accuracy: 0.8294\n",
      "Epoch 175/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3842 - accuracy: 0.8672 - val_loss: 0.5406 - val_accuracy: 0.8275\n",
      "Epoch 176/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3866 - accuracy: 0.8622 - val_loss: 0.5091 - val_accuracy: 0.8353\n",
      "Epoch 177/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3836 - accuracy: 0.8655 - val_loss: 0.5138 - val_accuracy: 0.8373\n",
      "Epoch 178/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3806 - accuracy: 0.8723 - val_loss: 0.5139 - val_accuracy: 0.8255\n",
      "Epoch 179/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3771 - accuracy: 0.8672 - val_loss: 0.5193 - val_accuracy: 0.8314\n",
      "Epoch 180/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3771 - accuracy: 0.8765 - val_loss: 0.5242 - val_accuracy: 0.8294\n",
      "Epoch 181/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3774 - accuracy: 0.8723 - val_loss: 0.5088 - val_accuracy: 0.8412\n",
      "Epoch 182/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3760 - accuracy: 0.8697 - val_loss: 0.5049 - val_accuracy: 0.8431\n",
      "Epoch 183/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3704 - accuracy: 0.8723 - val_loss: 0.5103 - val_accuracy: 0.8235\n",
      "Epoch 184/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3705 - accuracy: 0.8790 - val_loss: 0.5241 - val_accuracy: 0.8373\n",
      "Epoch 185/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3699 - accuracy: 0.8706 - val_loss: 0.5277 - val_accuracy: 0.8314\n",
      "Epoch 186/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3670 - accuracy: 0.8748 - val_loss: 0.5104 - val_accuracy: 0.8255\n",
      "Epoch 187/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3629 - accuracy: 0.8748 - val_loss: 0.5165 - val_accuracy: 0.8314\n",
      "Epoch 188/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3641 - accuracy: 0.8689 - val_loss: 0.5209 - val_accuracy: 0.8216\n",
      "Epoch 189/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3640 - accuracy: 0.8714 - val_loss: 0.5089 - val_accuracy: 0.8412\n",
      "Epoch 190/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3653 - accuracy: 0.8714 - val_loss: 0.5033 - val_accuracy: 0.8314\n",
      "Epoch 191/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3601 - accuracy: 0.8765 - val_loss: 0.5170 - val_accuracy: 0.8392\n",
      "Epoch 192/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3572 - accuracy: 0.8798 - val_loss: 0.5043 - val_accuracy: 0.8412\n",
      "Epoch 193/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3603 - accuracy: 0.8706 - val_loss: 0.4908 - val_accuracy: 0.8490\n",
      "Epoch 194/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3583 - accuracy: 0.8798 - val_loss: 0.5136 - val_accuracy: 0.8333\n",
      "Epoch 195/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3574 - accuracy: 0.8748 - val_loss: 0.4958 - val_accuracy: 0.8353\n",
      "Epoch 196/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3540 - accuracy: 0.8798 - val_loss: 0.4925 - val_accuracy: 0.8529\n",
      "Epoch 197/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3518 - accuracy: 0.8824 - val_loss: 0.5031 - val_accuracy: 0.8510\n",
      "Epoch 198/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3556 - accuracy: 0.8756 - val_loss: 0.5017 - val_accuracy: 0.8412\n",
      "Epoch 199/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3503 - accuracy: 0.8773 - val_loss: 0.4961 - val_accuracy: 0.8392\n",
      "Epoch 200/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3487 - accuracy: 0.8782 - val_loss: 0.5022 - val_accuracy: 0.8431\n",
      "Epoch 201/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3473 - accuracy: 0.8773 - val_loss: 0.4823 - val_accuracy: 0.8588\n",
      "Epoch 202/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3475 - accuracy: 0.8840 - val_loss: 0.5149 - val_accuracy: 0.8451\n",
      "Epoch 203/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3458 - accuracy: 0.8782 - val_loss: 0.4997 - val_accuracy: 0.8431\n",
      "Epoch 204/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3488 - accuracy: 0.8782 - val_loss: 0.4907 - val_accuracy: 0.8431\n",
      "Epoch 205/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3416 - accuracy: 0.8790 - val_loss: 0.5002 - val_accuracy: 0.8490\n",
      "Epoch 206/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3480 - accuracy: 0.8723 - val_loss: 0.4795 - val_accuracy: 0.8431\n",
      "Epoch 207/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3406 - accuracy: 0.8840 - val_loss: 0.4965 - val_accuracy: 0.8451\n",
      "Epoch 208/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3366 - accuracy: 0.8824 - val_loss: 0.4973 - val_accuracy: 0.8275\n",
      "Epoch 209/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3409 - accuracy: 0.8807 - val_loss: 0.4946 - val_accuracy: 0.8294\n",
      "Epoch 210/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3341 - accuracy: 0.8807 - val_loss: 0.5055 - val_accuracy: 0.8392\n",
      "Epoch 211/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3435 - accuracy: 0.8790 - val_loss: 0.4899 - val_accuracy: 0.8392\n",
      "Epoch 212/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3353 - accuracy: 0.8840 - val_loss: 0.5056 - val_accuracy: 0.8392\n",
      "Epoch 213/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3358 - accuracy: 0.8824 - val_loss: 0.4807 - val_accuracy: 0.8451\n",
      "Epoch 214/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3351 - accuracy: 0.8790 - val_loss: 0.4826 - val_accuracy: 0.8510\n",
      "Epoch 215/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3331 - accuracy: 0.8748 - val_loss: 0.4950 - val_accuracy: 0.8549\n",
      "Epoch 216/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3307 - accuracy: 0.8882 - val_loss: 0.5006 - val_accuracy: 0.8490\n",
      "Epoch 217/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3342 - accuracy: 0.8882 - val_loss: 0.4940 - val_accuracy: 0.8451\n",
      "Epoch 218/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3311 - accuracy: 0.8866 - val_loss: 0.5034 - val_accuracy: 0.8353\n",
      "Epoch 219/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3289 - accuracy: 0.8849 - val_loss: 0.4831 - val_accuracy: 0.8431\n",
      "Epoch 220/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3253 - accuracy: 0.8832 - val_loss: 0.4923 - val_accuracy: 0.8529\n",
      "Epoch 221/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3331 - accuracy: 0.8832 - val_loss: 0.4911 - val_accuracy: 0.8451\n",
      "Epoch 222/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3299 - accuracy: 0.8857 - val_loss: 0.4807 - val_accuracy: 0.8471\n",
      "Epoch 223/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3304 - accuracy: 0.8807 - val_loss: 0.4863 - val_accuracy: 0.8569\n",
      "Epoch 224/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3204 - accuracy: 0.8874 - val_loss: 0.5112 - val_accuracy: 0.8353\n",
      "Epoch 225/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3257 - accuracy: 0.8857 - val_loss: 0.4858 - val_accuracy: 0.8471\n",
      "Epoch 226/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3245 - accuracy: 0.8840 - val_loss: 0.4779 - val_accuracy: 0.8569\n",
      "Epoch 227/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3209 - accuracy: 0.8832 - val_loss: 0.4955 - val_accuracy: 0.8608\n",
      "Epoch 228/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3190 - accuracy: 0.8866 - val_loss: 0.4781 - val_accuracy: 0.8529\n",
      "Epoch 229/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3245 - accuracy: 0.8824 - val_loss: 0.4822 - val_accuracy: 0.8569\n",
      "Epoch 230/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3232 - accuracy: 0.8798 - val_loss: 0.4788 - val_accuracy: 0.8510\n",
      "Epoch 231/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3151 - accuracy: 0.8882 - val_loss: 0.4937 - val_accuracy: 0.8431\n",
      "Epoch 232/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3197 - accuracy: 0.8882 - val_loss: 0.4800 - val_accuracy: 0.8569\n",
      "Epoch 233/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3210 - accuracy: 0.8832 - val_loss: 0.4653 - val_accuracy: 0.8510\n",
      "Epoch 234/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3181 - accuracy: 0.8866 - val_loss: 0.4822 - val_accuracy: 0.8588\n",
      "Epoch 235/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3189 - accuracy: 0.8857 - val_loss: 0.4841 - val_accuracy: 0.8588\n",
      "Epoch 236/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3144 - accuracy: 0.8891 - val_loss: 0.4881 - val_accuracy: 0.8412\n",
      "Epoch 237/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3166 - accuracy: 0.8891 - val_loss: 0.4802 - val_accuracy: 0.8569\n",
      "Epoch 238/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3135 - accuracy: 0.8874 - val_loss: 0.4748 - val_accuracy: 0.8529\n",
      "Epoch 239/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3180 - accuracy: 0.8849 - val_loss: 0.4722 - val_accuracy: 0.8627\n",
      "Epoch 240/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3137 - accuracy: 0.8899 - val_loss: 0.4842 - val_accuracy: 0.8529\n",
      "Epoch 241/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3096 - accuracy: 0.8891 - val_loss: 0.4791 - val_accuracy: 0.8529\n",
      "Epoch 242/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3073 - accuracy: 0.8840 - val_loss: 0.4911 - val_accuracy: 0.8431\n",
      "Epoch 243/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3104 - accuracy: 0.8832 - val_loss: 0.4612 - val_accuracy: 0.8588\n",
      "Epoch 244/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3091 - accuracy: 0.8908 - val_loss: 0.4691 - val_accuracy: 0.8510\n",
      "Epoch 245/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3083 - accuracy: 0.8958 - val_loss: 0.4788 - val_accuracy: 0.8529\n",
      "Epoch 246/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3112 - accuracy: 0.8933 - val_loss: 0.4762 - val_accuracy: 0.8392\n",
      "Epoch 247/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3105 - accuracy: 0.8866 - val_loss: 0.4806 - val_accuracy: 0.8412\n",
      "Epoch 248/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3098 - accuracy: 0.8874 - val_loss: 0.4691 - val_accuracy: 0.8549\n",
      "Epoch 249/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3068 - accuracy: 0.8958 - val_loss: 0.4699 - val_accuracy: 0.8549\n",
      "Epoch 250/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3086 - accuracy: 0.8882 - val_loss: 0.4735 - val_accuracy: 0.8510\n",
      "Epoch 251/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3066 - accuracy: 0.8950 - val_loss: 0.4733 - val_accuracy: 0.8549\n",
      "Epoch 252/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3009 - accuracy: 0.8941 - val_loss: 0.4768 - val_accuracy: 0.8490\n",
      "Epoch 253/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3034 - accuracy: 0.8874 - val_loss: 0.4710 - val_accuracy: 0.8490\n",
      "Epoch 254/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3041 - accuracy: 0.8908 - val_loss: 0.4899 - val_accuracy: 0.8451\n",
      "Epoch 255/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3049 - accuracy: 0.8891 - val_loss: 0.4761 - val_accuracy: 0.8451\n",
      "Epoch 256/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3010 - accuracy: 0.8924 - val_loss: 0.4687 - val_accuracy: 0.8451\n",
      "Epoch 257/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2986 - accuracy: 0.8950 - val_loss: 0.4976 - val_accuracy: 0.8569\n",
      "Epoch 258/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3044 - accuracy: 0.8882 - val_loss: 0.4716 - val_accuracy: 0.8569\n",
      "Epoch 259/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2966 - accuracy: 0.8983 - val_loss: 0.4795 - val_accuracy: 0.8569\n",
      "Epoch 260/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3003 - accuracy: 0.8941 - val_loss: 0.4711 - val_accuracy: 0.8569\n",
      "Epoch 261/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2958 - accuracy: 0.8891 - val_loss: 0.4774 - val_accuracy: 0.8549\n",
      "Epoch 262/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3043 - accuracy: 0.8899 - val_loss: 0.4677 - val_accuracy: 0.8608\n",
      "Epoch 263/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3029 - accuracy: 0.8924 - val_loss: 0.4682 - val_accuracy: 0.8549\n",
      "Epoch 264/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3002 - accuracy: 0.9000 - val_loss: 0.4671 - val_accuracy: 0.8647\n",
      "Epoch 265/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2962 - accuracy: 0.8916 - val_loss: 0.4673 - val_accuracy: 0.8569\n",
      "Epoch 266/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2986 - accuracy: 0.8924 - val_loss: 0.4595 - val_accuracy: 0.8608\n",
      "Epoch 267/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2921 - accuracy: 0.8941 - val_loss: 0.4662 - val_accuracy: 0.8549\n",
      "Epoch 268/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2946 - accuracy: 0.8966 - val_loss: 0.4660 - val_accuracy: 0.8686\n",
      "Epoch 269/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2954 - accuracy: 0.8958 - val_loss: 0.4718 - val_accuracy: 0.8588\n",
      "Epoch 270/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2953 - accuracy: 0.8908 - val_loss: 0.4647 - val_accuracy: 0.8431\n",
      "Epoch 271/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2955 - accuracy: 0.8924 - val_loss: 0.4647 - val_accuracy: 0.8588\n",
      "Epoch 272/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2933 - accuracy: 0.8916 - val_loss: 0.4796 - val_accuracy: 0.8588\n",
      "Epoch 273/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2909 - accuracy: 0.8966 - val_loss: 0.4736 - val_accuracy: 0.8431\n",
      "Epoch 274/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2951 - accuracy: 0.8983 - val_loss: 0.4624 - val_accuracy: 0.8471\n",
      "Epoch 275/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2928 - accuracy: 0.8924 - val_loss: 0.4544 - val_accuracy: 0.8608\n",
      "Epoch 276/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2889 - accuracy: 0.8966 - val_loss: 0.4765 - val_accuracy: 0.8490\n",
      "Epoch 277/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2939 - accuracy: 0.8908 - val_loss: 0.4626 - val_accuracy: 0.8686\n",
      "Epoch 278/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2901 - accuracy: 0.8933 - val_loss: 0.4614 - val_accuracy: 0.8608\n",
      "Epoch 279/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2867 - accuracy: 0.8975 - val_loss: 0.4658 - val_accuracy: 0.8588\n",
      "Epoch 280/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2908 - accuracy: 0.8966 - val_loss: 0.4650 - val_accuracy: 0.8588\n",
      "Epoch 281/500\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.2836 - accuracy: 0.90 - 1s 4ms/step - loss: 0.2931 - accuracy: 0.8958 - val_loss: 0.4608 - val_accuracy: 0.8510\n",
      "Epoch 282/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2873 - accuracy: 0.9017 - val_loss: 0.4617 - val_accuracy: 0.8647\n",
      "Epoch 283/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2921 - accuracy: 0.8933 - val_loss: 0.4561 - val_accuracy: 0.8490\n",
      "Epoch 284/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2863 - accuracy: 0.8958 - val_loss: 0.4757 - val_accuracy: 0.8314\n",
      "Epoch 285/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2888 - accuracy: 0.8966 - val_loss: 0.4727 - val_accuracy: 0.8451\n",
      "Epoch 286/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2880 - accuracy: 0.8983 - val_loss: 0.4708 - val_accuracy: 0.8392\n",
      "Epoch 287/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2817 - accuracy: 0.9000 - val_loss: 0.4589 - val_accuracy: 0.8608\n",
      "Epoch 288/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2864 - accuracy: 0.8950 - val_loss: 0.4650 - val_accuracy: 0.8529\n",
      "Epoch 289/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2852 - accuracy: 0.9025 - val_loss: 0.4754 - val_accuracy: 0.8588\n",
      "Epoch 290/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2913 - accuracy: 0.8924 - val_loss: 0.4551 - val_accuracy: 0.8471\n",
      "Epoch 291/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2845 - accuracy: 0.9025 - val_loss: 0.4638 - val_accuracy: 0.8549\n",
      "Epoch 292/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2804 - accuracy: 0.9034 - val_loss: 0.4851 - val_accuracy: 0.8471\n",
      "Epoch 293/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2837 - accuracy: 0.9025 - val_loss: 0.4751 - val_accuracy: 0.8529\n",
      "Epoch 294/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2876 - accuracy: 0.8941 - val_loss: 0.4642 - val_accuracy: 0.8471\n",
      "Epoch 295/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2841 - accuracy: 0.9034 - val_loss: 0.4483 - val_accuracy: 0.8608\n",
      "Epoch 296/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2841 - accuracy: 0.8975 - val_loss: 0.4557 - val_accuracy: 0.8529\n",
      "Epoch 297/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2808 - accuracy: 0.8983 - val_loss: 0.4651 - val_accuracy: 0.8490\n",
      "Epoch 298/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2842 - accuracy: 0.8941 - val_loss: 0.4671 - val_accuracy: 0.8569\n",
      "Epoch 299/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2809 - accuracy: 0.9000 - val_loss: 0.4619 - val_accuracy: 0.8647\n",
      "Epoch 300/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2856 - accuracy: 0.8975 - val_loss: 0.4615 - val_accuracy: 0.8608\n",
      "Epoch 301/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2822 - accuracy: 0.8983 - val_loss: 0.4477 - val_accuracy: 0.8549\n",
      "Epoch 302/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2817 - accuracy: 0.8992 - val_loss: 0.4566 - val_accuracy: 0.8627\n",
      "Epoch 303/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2809 - accuracy: 0.9042 - val_loss: 0.4709 - val_accuracy: 0.8392\n",
      "Epoch 304/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2759 - accuracy: 0.9017 - val_loss: 0.4739 - val_accuracy: 0.8627\n",
      "Epoch 305/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2810 - accuracy: 0.9000 - val_loss: 0.4519 - val_accuracy: 0.8627\n",
      "Epoch 306/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2812 - accuracy: 0.8992 - val_loss: 0.4487 - val_accuracy: 0.8667\n",
      "Epoch 307/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2834 - accuracy: 0.8983 - val_loss: 0.4563 - val_accuracy: 0.8608\n",
      "Epoch 308/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2760 - accuracy: 0.9025 - val_loss: 0.4886 - val_accuracy: 0.8608\n",
      "Epoch 309/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2792 - accuracy: 0.8975 - val_loss: 0.4567 - val_accuracy: 0.8490\n",
      "Epoch 310/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2822 - accuracy: 0.9000 - val_loss: 0.4555 - val_accuracy: 0.8549\n",
      "Epoch 311/500\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.2836 - accuracy: 0.89 - 1s 4ms/step - loss: 0.2793 - accuracy: 0.8941 - val_loss: 0.4604 - val_accuracy: 0.8647\n",
      "Epoch 312/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2770 - accuracy: 0.9034 - val_loss: 0.4546 - val_accuracy: 0.8588\n",
      "Epoch 313/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2783 - accuracy: 0.9017 - val_loss: 0.4533 - val_accuracy: 0.8569\n",
      "Epoch 314/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2793 - accuracy: 0.9017 - val_loss: 0.4634 - val_accuracy: 0.8627\n",
      "Epoch 315/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2764 - accuracy: 0.8992 - val_loss: 0.4776 - val_accuracy: 0.8569\n",
      "Epoch 316/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2800 - accuracy: 0.9017 - val_loss: 0.4576 - val_accuracy: 0.8431\n",
      "Epoch 317/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2724 - accuracy: 0.9109 - val_loss: 0.4551 - val_accuracy: 0.8490\n",
      "Epoch 318/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2751 - accuracy: 0.9025 - val_loss: 0.4690 - val_accuracy: 0.8490\n",
      "Epoch 319/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2721 - accuracy: 0.9042 - val_loss: 0.4732 - val_accuracy: 0.8451\n",
      "Epoch 320/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2800 - accuracy: 0.8992 - val_loss: 0.4595 - val_accuracy: 0.8647\n",
      "Epoch 321/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2756 - accuracy: 0.9000 - val_loss: 0.4617 - val_accuracy: 0.8647\n",
      "Epoch 322/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2742 - accuracy: 0.8983 - val_loss: 0.4579 - val_accuracy: 0.8608\n",
      "Epoch 323/500\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.2745 - accuracy: 0.90 - 1s 4ms/step - loss: 0.2753 - accuracy: 0.9000 - val_loss: 0.4443 - val_accuracy: 0.8647\n",
      "Epoch 324/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2731 - accuracy: 0.9092 - val_loss: 0.4622 - val_accuracy: 0.8549\n",
      "Epoch 325/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2779 - accuracy: 0.9017 - val_loss: 0.4522 - val_accuracy: 0.8627\n",
      "Epoch 326/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2763 - accuracy: 0.9025 - val_loss: 0.4528 - val_accuracy: 0.8588\n",
      "Epoch 327/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2755 - accuracy: 0.9000 - val_loss: 0.4588 - val_accuracy: 0.8510\n",
      "Epoch 328/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2725 - accuracy: 0.8983 - val_loss: 0.4581 - val_accuracy: 0.8608\n",
      "Epoch 329/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2710 - accuracy: 0.9042 - val_loss: 0.4516 - val_accuracy: 0.8588\n",
      "Epoch 330/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2773 - accuracy: 0.9017 - val_loss: 0.4492 - val_accuracy: 0.8529\n",
      "Epoch 331/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2714 - accuracy: 0.9017 - val_loss: 0.4696 - val_accuracy: 0.8549\n",
      "Epoch 332/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2719 - accuracy: 0.9000 - val_loss: 0.4558 - val_accuracy: 0.8647\n",
      "Epoch 333/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2712 - accuracy: 0.9059 - val_loss: 0.4530 - val_accuracy: 0.8725\n",
      "Epoch 334/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2722 - accuracy: 0.8992 - val_loss: 0.4629 - val_accuracy: 0.8608\n",
      "Epoch 335/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2725 - accuracy: 0.9042 - val_loss: 0.4677 - val_accuracy: 0.8725\n",
      "Epoch 336/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2724 - accuracy: 0.9059 - val_loss: 0.4558 - val_accuracy: 0.8549\n",
      "Epoch 337/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2661 - accuracy: 0.9034 - val_loss: 0.4539 - val_accuracy: 0.8608\n",
      "Epoch 338/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2713 - accuracy: 0.9008 - val_loss: 0.4488 - val_accuracy: 0.8490\n",
      "Epoch 339/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2674 - accuracy: 0.9118 - val_loss: 0.4588 - val_accuracy: 0.8608\n",
      "Epoch 340/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2720 - accuracy: 0.9008 - val_loss: 0.4582 - val_accuracy: 0.8647\n",
      "Epoch 341/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2735 - accuracy: 0.9042 - val_loss: 0.4497 - val_accuracy: 0.8608\n",
      "Epoch 342/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2693 - accuracy: 0.9059 - val_loss: 0.4600 - val_accuracy: 0.8510\n",
      "Epoch 343/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2714 - accuracy: 0.9008 - val_loss: 0.4612 - val_accuracy: 0.8588\n",
      "Epoch 344/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2688 - accuracy: 0.9000 - val_loss: 0.4426 - val_accuracy: 0.8588\n",
      "Epoch 345/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2658 - accuracy: 0.9067 - val_loss: 0.4691 - val_accuracy: 0.8588\n",
      "Epoch 346/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2701 - accuracy: 0.9000 - val_loss: 0.4493 - val_accuracy: 0.8549\n",
      "Epoch 347/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2709 - accuracy: 0.8992 - val_loss: 0.4400 - val_accuracy: 0.8686\n",
      "Epoch 348/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2667 - accuracy: 0.9017 - val_loss: 0.4497 - val_accuracy: 0.8667\n",
      "Epoch 349/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2711 - accuracy: 0.9034 - val_loss: 0.4589 - val_accuracy: 0.8667\n",
      "Epoch 350/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2626 - accuracy: 0.8975 - val_loss: 0.4671 - val_accuracy: 0.8667\n",
      "Epoch 351/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2682 - accuracy: 0.9042 - val_loss: 0.4555 - val_accuracy: 0.8647\n",
      "Epoch 352/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2672 - accuracy: 0.9059 - val_loss: 0.4557 - val_accuracy: 0.8627\n",
      "Epoch 353/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2645 - accuracy: 0.9059 - val_loss: 0.4590 - val_accuracy: 0.8627\n",
      "Epoch 354/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2677 - accuracy: 0.9034 - val_loss: 0.4422 - val_accuracy: 0.8608\n",
      "Epoch 355/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2678 - accuracy: 0.8983 - val_loss: 0.4499 - val_accuracy: 0.8627\n",
      "Epoch 356/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2642 - accuracy: 0.9050 - val_loss: 0.4609 - val_accuracy: 0.8549\n",
      "Epoch 357/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2619 - accuracy: 0.9042 - val_loss: 0.4568 - val_accuracy: 0.8667\n",
      "Epoch 358/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2689 - accuracy: 0.9084 - val_loss: 0.4544 - val_accuracy: 0.8627\n",
      "Epoch 359/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2664 - accuracy: 0.9008 - val_loss: 0.4470 - val_accuracy: 0.8627\n",
      "Epoch 360/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2647 - accuracy: 0.9017 - val_loss: 0.4529 - val_accuracy: 0.8608\n",
      "Epoch 361/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2683 - accuracy: 0.9008 - val_loss: 0.4487 - val_accuracy: 0.8647\n",
      "Epoch 362/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2665 - accuracy: 0.9025 - val_loss: 0.4470 - val_accuracy: 0.8765\n",
      "Epoch 363/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2655 - accuracy: 0.9067 - val_loss: 0.4475 - val_accuracy: 0.8627\n",
      "Epoch 364/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2644 - accuracy: 0.9017 - val_loss: 0.4571 - val_accuracy: 0.8608\n",
      "Epoch 365/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2622 - accuracy: 0.9067 - val_loss: 0.4435 - val_accuracy: 0.8706\n",
      "Epoch 366/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2616 - accuracy: 0.9067 - val_loss: 0.4690 - val_accuracy: 0.8686\n",
      "Epoch 367/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2643 - accuracy: 0.9008 - val_loss: 0.4568 - val_accuracy: 0.8588\n",
      "Epoch 368/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2641 - accuracy: 0.9025 - val_loss: 0.4636 - val_accuracy: 0.8471\n",
      "Epoch 369/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2617 - accuracy: 0.9034 - val_loss: 0.4534 - val_accuracy: 0.8627\n",
      "Epoch 370/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2600 - accuracy: 0.9050 - val_loss: 0.4527 - val_accuracy: 0.8627\n",
      "Epoch 371/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2672 - accuracy: 0.9000 - val_loss: 0.4553 - val_accuracy: 0.8529\n",
      "Epoch 372/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2628 - accuracy: 0.9067 - val_loss: 0.4570 - val_accuracy: 0.8686\n",
      "Epoch 373/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2602 - accuracy: 0.9042 - val_loss: 0.4697 - val_accuracy: 0.8569\n",
      "Epoch 374/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2633 - accuracy: 0.9092 - val_loss: 0.4682 - val_accuracy: 0.8667\n",
      "Epoch 375/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2622 - accuracy: 0.9084 - val_loss: 0.4480 - val_accuracy: 0.8706\n",
      "Epoch 376/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2612 - accuracy: 0.8992 - val_loss: 0.4701 - val_accuracy: 0.8529\n",
      "Epoch 377/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2619 - accuracy: 0.9017 - val_loss: 0.4501 - val_accuracy: 0.8549\n",
      "Epoch 378/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2612 - accuracy: 0.9067 - val_loss: 0.4544 - val_accuracy: 0.8784\n",
      "Epoch 379/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2623 - accuracy: 0.9076 - val_loss: 0.4729 - val_accuracy: 0.8549\n",
      "Epoch 380/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2636 - accuracy: 0.9067 - val_loss: 0.4631 - val_accuracy: 0.8647\n",
      "Epoch 381/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2594 - accuracy: 0.9101 - val_loss: 0.4472 - val_accuracy: 0.8588\n",
      "Epoch 382/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2629 - accuracy: 0.9059 - val_loss: 0.4535 - val_accuracy: 0.8627\n",
      "Epoch 383/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2610 - accuracy: 0.9059 - val_loss: 0.4688 - val_accuracy: 0.8745\n",
      "Epoch 384/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2642 - accuracy: 0.9118 - val_loss: 0.4432 - val_accuracy: 0.8627\n",
      "Epoch 385/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2619 - accuracy: 0.9034 - val_loss: 0.4515 - val_accuracy: 0.8784\n",
      "Epoch 386/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2623 - accuracy: 0.9067 - val_loss: 0.4510 - val_accuracy: 0.8725\n",
      "Epoch 387/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2625 - accuracy: 0.9109 - val_loss: 0.4445 - val_accuracy: 0.8647\n",
      "Epoch 388/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2591 - accuracy: 0.9050 - val_loss: 0.4603 - val_accuracy: 0.8608\n",
      "Epoch 389/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2625 - accuracy: 0.9034 - val_loss: 0.4574 - val_accuracy: 0.8608\n",
      "Epoch 390/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2639 - accuracy: 0.9059 - val_loss: 0.4500 - val_accuracy: 0.8725\n",
      "Epoch 391/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2604 - accuracy: 0.9059 - val_loss: 0.4697 - val_accuracy: 0.8529\n",
      "Epoch 392/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2614 - accuracy: 0.9067 - val_loss: 0.4554 - val_accuracy: 0.8588\n",
      "Epoch 393/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2620 - accuracy: 0.9008 - val_loss: 0.4482 - val_accuracy: 0.8706\n",
      "Epoch 394/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2598 - accuracy: 0.9025 - val_loss: 0.4492 - val_accuracy: 0.8627\n",
      "Epoch 395/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2587 - accuracy: 0.9076 - val_loss: 0.4547 - val_accuracy: 0.8686\n",
      "Epoch 396/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2571 - accuracy: 0.9084 - val_loss: 0.4599 - val_accuracy: 0.8667\n",
      "Epoch 397/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2589 - accuracy: 0.9034 - val_loss: 0.4570 - val_accuracy: 0.8647\n",
      "Epoch 398/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2648 - accuracy: 0.9025 - val_loss: 0.4447 - val_accuracy: 0.8647\n",
      "Epoch 399/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2612 - accuracy: 0.9067 - val_loss: 0.4464 - val_accuracy: 0.8608\n",
      "Epoch 400/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2575 - accuracy: 0.9084 - val_loss: 0.4444 - val_accuracy: 0.8686\n",
      "Epoch 401/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2601 - accuracy: 0.9084 - val_loss: 0.4340 - val_accuracy: 0.8706\n",
      "Epoch 402/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2604 - accuracy: 0.9034 - val_loss: 0.4548 - val_accuracy: 0.8510\n",
      "Epoch 403/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2619 - accuracy: 0.9084 - val_loss: 0.4469 - val_accuracy: 0.8667\n",
      "Epoch 404/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2570 - accuracy: 0.9050 - val_loss: 0.4588 - val_accuracy: 0.8667\n",
      "Epoch 405/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2656 - accuracy: 0.9017 - val_loss: 0.4357 - val_accuracy: 0.8667\n",
      "Epoch 406/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2579 - accuracy: 0.9101 - val_loss: 0.4488 - val_accuracy: 0.8745\n",
      "Epoch 407/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2644 - accuracy: 0.9000 - val_loss: 0.4301 - val_accuracy: 0.8725\n",
      "Epoch 408/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2559 - accuracy: 0.9017 - val_loss: 0.4512 - val_accuracy: 0.8588\n",
      "Epoch 409/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2622 - accuracy: 0.9084 - val_loss: 0.4377 - val_accuracy: 0.8706\n",
      "Epoch 410/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2573 - accuracy: 0.9000 - val_loss: 0.4518 - val_accuracy: 0.8588\n",
      "Epoch 411/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2589 - accuracy: 0.9017 - val_loss: 0.4488 - val_accuracy: 0.8627\n",
      "Epoch 412/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2591 - accuracy: 0.9017 - val_loss: 0.4467 - val_accuracy: 0.8725\n",
      "Epoch 413/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2563 - accuracy: 0.9034 - val_loss: 0.4445 - val_accuracy: 0.8706\n",
      "Epoch 414/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2570 - accuracy: 0.9092 - val_loss: 0.4459 - val_accuracy: 0.8608\n",
      "Epoch 415/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2578 - accuracy: 0.8992 - val_loss: 0.4378 - val_accuracy: 0.8608\n",
      "Epoch 416/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2588 - accuracy: 0.9067 - val_loss: 0.4530 - val_accuracy: 0.8647\n",
      "Epoch 417/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2598 - accuracy: 0.9008 - val_loss: 0.4460 - val_accuracy: 0.8686\n",
      "Epoch 418/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2569 - accuracy: 0.9050 - val_loss: 0.4435 - val_accuracy: 0.8745\n",
      "Epoch 419/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2571 - accuracy: 0.9109 - val_loss: 0.4457 - val_accuracy: 0.8588\n",
      "Epoch 420/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2596 - accuracy: 0.9050 - val_loss: 0.4425 - val_accuracy: 0.8686\n",
      "Epoch 421/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2530 - accuracy: 0.9034 - val_loss: 0.4530 - val_accuracy: 0.8647\n",
      "Epoch 422/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2578 - accuracy: 0.9050 - val_loss: 0.4448 - val_accuracy: 0.8647\n",
      "Epoch 423/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2566 - accuracy: 0.9000 - val_loss: 0.4453 - val_accuracy: 0.8706\n",
      "Epoch 424/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2533 - accuracy: 0.9059 - val_loss: 0.4531 - val_accuracy: 0.8647\n",
      "Epoch 425/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2536 - accuracy: 0.9050 - val_loss: 0.4436 - val_accuracy: 0.8745\n",
      "Epoch 426/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2576 - accuracy: 0.9017 - val_loss: 0.4364 - val_accuracy: 0.8608\n",
      "Epoch 427/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2525 - accuracy: 0.9084 - val_loss: 0.4424 - val_accuracy: 0.8745\n",
      "Epoch 428/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2567 - accuracy: 0.9000 - val_loss: 0.4463 - val_accuracy: 0.8667\n",
      "Epoch 429/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2503 - accuracy: 0.9101 - val_loss: 0.4453 - val_accuracy: 0.8667\n",
      "Epoch 430/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2563 - accuracy: 0.9059 - val_loss: 0.4360 - val_accuracy: 0.8686\n",
      "Epoch 431/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2542 - accuracy: 0.9067 - val_loss: 0.4240 - val_accuracy: 0.8647\n",
      "Epoch 432/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2522 - accuracy: 0.9034 - val_loss: 0.4477 - val_accuracy: 0.8686\n",
      "Epoch 433/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2547 - accuracy: 0.9042 - val_loss: 0.4412 - val_accuracy: 0.8725\n",
      "Epoch 434/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2592 - accuracy: 0.9059 - val_loss: 0.4275 - val_accuracy: 0.8706\n",
      "Epoch 435/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2553 - accuracy: 0.9034 - val_loss: 0.4392 - val_accuracy: 0.8706\n",
      "Epoch 436/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2529 - accuracy: 0.9076 - val_loss: 0.4398 - val_accuracy: 0.8745\n",
      "Epoch 437/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2518 - accuracy: 0.9067 - val_loss: 0.4383 - val_accuracy: 0.8686\n",
      "Epoch 438/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2540 - accuracy: 0.9000 - val_loss: 0.4303 - val_accuracy: 0.8686\n",
      "Epoch 439/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2501 - accuracy: 0.9042 - val_loss: 0.4371 - val_accuracy: 0.8627\n",
      "Epoch 440/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2497 - accuracy: 0.9067 - val_loss: 0.4451 - val_accuracy: 0.8647\n",
      "Epoch 441/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2507 - accuracy: 0.9101 - val_loss: 0.4374 - val_accuracy: 0.8608\n",
      "Epoch 442/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2499 - accuracy: 0.9067 - val_loss: 0.4495 - val_accuracy: 0.8706\n",
      "Epoch 443/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2500 - accuracy: 0.9109 - val_loss: 0.4622 - val_accuracy: 0.8549\n",
      "Epoch 444/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2538 - accuracy: 0.9000 - val_loss: 0.4343 - val_accuracy: 0.8706\n",
      "Epoch 445/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2544 - accuracy: 0.9042 - val_loss: 0.4376 - val_accuracy: 0.8725\n",
      "Epoch 446/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2532 - accuracy: 0.9118 - val_loss: 0.4363 - val_accuracy: 0.8725\n",
      "Epoch 447/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2525 - accuracy: 0.9059 - val_loss: 0.4355 - val_accuracy: 0.8725\n",
      "Epoch 448/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2522 - accuracy: 0.9076 - val_loss: 0.4519 - val_accuracy: 0.8686\n",
      "Epoch 449/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2556 - accuracy: 0.9050 - val_loss: 0.4447 - val_accuracy: 0.8706\n",
      "Epoch 450/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2474 - accuracy: 0.9067 - val_loss: 0.4472 - val_accuracy: 0.8647\n",
      "Epoch 451/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2547 - accuracy: 0.9050 - val_loss: 0.4358 - val_accuracy: 0.8725\n",
      "Epoch 452/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2523 - accuracy: 0.9050 - val_loss: 0.4289 - val_accuracy: 0.8784\n",
      "Epoch 453/500\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.2537 - accuracy: 0.91 - 1s 4ms/step - loss: 0.2557 - accuracy: 0.9109 - val_loss: 0.4384 - val_accuracy: 0.8706\n",
      "Epoch 454/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2548 - accuracy: 0.9092 - val_loss: 0.4321 - val_accuracy: 0.8784\n",
      "Epoch 455/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2516 - accuracy: 0.9109 - val_loss: 0.4413 - val_accuracy: 0.8627\n",
      "Epoch 456/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2522 - accuracy: 0.9034 - val_loss: 0.4384 - val_accuracy: 0.8725\n",
      "Epoch 457/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2488 - accuracy: 0.9109 - val_loss: 0.4479 - val_accuracy: 0.8706\n",
      "Epoch 458/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2550 - accuracy: 0.9059 - val_loss: 0.4302 - val_accuracy: 0.8686\n",
      "Epoch 459/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2482 - accuracy: 0.9101 - val_loss: 0.4279 - val_accuracy: 0.8667\n",
      "Epoch 460/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2498 - accuracy: 0.9050 - val_loss: 0.4457 - val_accuracy: 0.8765\n",
      "Epoch 461/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2520 - accuracy: 0.9118 - val_loss: 0.4364 - val_accuracy: 0.8765\n",
      "Epoch 462/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2542 - accuracy: 0.9042 - val_loss: 0.4243 - val_accuracy: 0.8627\n",
      "Epoch 463/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2476 - accuracy: 0.9126 - val_loss: 0.4430 - val_accuracy: 0.8745\n",
      "Epoch 464/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2481 - accuracy: 0.9084 - val_loss: 0.4405 - val_accuracy: 0.8647\n",
      "Epoch 465/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2541 - accuracy: 0.9092 - val_loss: 0.4319 - val_accuracy: 0.8725\n",
      "Epoch 466/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2494 - accuracy: 0.9034 - val_loss: 0.4447 - val_accuracy: 0.8686\n",
      "Epoch 467/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2482 - accuracy: 0.9084 - val_loss: 0.4497 - val_accuracy: 0.8569\n",
      "Epoch 468/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2469 - accuracy: 0.9092 - val_loss: 0.4472 - val_accuracy: 0.8745\n",
      "Epoch 469/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2576 - accuracy: 0.9042 - val_loss: 0.4408 - val_accuracy: 0.8706\n",
      "Epoch 470/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2511 - accuracy: 0.9000 - val_loss: 0.4306 - val_accuracy: 0.8804\n",
      "Epoch 471/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2462 - accuracy: 0.9059 - val_loss: 0.4265 - val_accuracy: 0.8667\n",
      "Epoch 472/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2498 - accuracy: 0.9143 - val_loss: 0.4199 - val_accuracy: 0.8706\n",
      "Epoch 473/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2503 - accuracy: 0.9084 - val_loss: 0.4342 - val_accuracy: 0.8765\n",
      "Epoch 474/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2511 - accuracy: 0.9067 - val_loss: 0.4300 - val_accuracy: 0.8725\n",
      "Epoch 475/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2491 - accuracy: 0.9084 - val_loss: 0.4298 - val_accuracy: 0.8706\n",
      "Epoch 476/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2480 - accuracy: 0.9101 - val_loss: 0.4269 - val_accuracy: 0.8784\n",
      "Epoch 477/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2399 - accuracy: 0.9143 - val_loss: 0.4349 - val_accuracy: 0.8745\n",
      "Epoch 478/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2516 - accuracy: 0.9101 - val_loss: 0.4234 - val_accuracy: 0.8647\n",
      "Epoch 479/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2512 - accuracy: 0.9084 - val_loss: 0.4353 - val_accuracy: 0.8647\n",
      "Epoch 480/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2508 - accuracy: 0.9084 - val_loss: 0.4364 - val_accuracy: 0.8745\n",
      "Epoch 481/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2506 - accuracy: 0.9025 - val_loss: 0.4347 - val_accuracy: 0.8843\n",
      "Epoch 482/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2497 - accuracy: 0.9067 - val_loss: 0.4356 - val_accuracy: 0.8784\n",
      "Epoch 483/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2469 - accuracy: 0.9059 - val_loss: 0.4375 - val_accuracy: 0.8706\n",
      "Epoch 484/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2490 - accuracy: 0.9017 - val_loss: 0.4298 - val_accuracy: 0.8745\n",
      "Epoch 485/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2449 - accuracy: 0.9050 - val_loss: 0.4316 - val_accuracy: 0.8863\n",
      "Epoch 486/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2493 - accuracy: 0.9118 - val_loss: 0.4390 - val_accuracy: 0.8824\n",
      "Epoch 487/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2453 - accuracy: 0.9084 - val_loss: 0.4414 - val_accuracy: 0.8647\n",
      "Epoch 488/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2501 - accuracy: 0.9076 - val_loss: 0.4209 - val_accuracy: 0.8843\n",
      "Epoch 489/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2493 - accuracy: 0.9134 - val_loss: 0.4361 - val_accuracy: 0.8745\n",
      "Epoch 490/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2473 - accuracy: 0.9042 - val_loss: 0.4512 - val_accuracy: 0.8804\n",
      "Epoch 491/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2486 - accuracy: 0.9076 - val_loss: 0.4224 - val_accuracy: 0.8745\n",
      "Epoch 492/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2457 - accuracy: 0.9109 - val_loss: 0.4200 - val_accuracy: 0.8706\n",
      "Epoch 493/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2495 - accuracy: 0.9067 - val_loss: 0.4220 - val_accuracy: 0.8686\n",
      "Epoch 494/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2502 - accuracy: 0.9109 - val_loss: 0.4242 - val_accuracy: 0.8784\n",
      "Epoch 495/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2470 - accuracy: 0.9126 - val_loss: 0.4477 - val_accuracy: 0.8725\n",
      "Epoch 496/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2469 - accuracy: 0.9059 - val_loss: 0.4267 - val_accuracy: 0.8784\n",
      "Epoch 497/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2497 - accuracy: 0.9076 - val_loss: 0.4301 - val_accuracy: 0.8765\n",
      "Epoch 498/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2445 - accuracy: 0.9092 - val_loss: 0.4376 - val_accuracy: 0.8569\n",
      "Epoch 499/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2499 - accuracy: 0.9092 - val_loss: 0.4348 - val_accuracy: 0.8667\n",
      "Epoch 500/500\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2494 - accuracy: 0.9059 - val_loss: 0.4279 - val_accuracy: 0.8804\n",
      "(365, 15)\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.1287 - accuracy: 0.7699\n",
      "loss :  1.1286873817443848\n",
      "accuracy :  0.7698630094528198\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.92      0.65        25\n",
      "         1.0       0.84      0.55      0.67        29\n",
      "         2.0       0.81      0.77      0.79        22\n",
      "         3.0       0.91      0.95      0.93        22\n",
      "         4.0       0.93      0.59      0.72        22\n",
      "         5.0       0.92      1.00      0.96        24\n",
      "         6.0       0.65      0.83      0.73        18\n",
      "         7.0       0.65      0.96      0.77        25\n",
      "         8.0       0.67      0.46      0.55        26\n",
      "         9.0       0.70      0.73      0.72        26\n",
      "        10.0       0.58      0.64      0.61        22\n",
      "        11.0       1.00      0.82      0.90        22\n",
      "        12.0       0.83      0.89      0.86        27\n",
      "        13.0       0.71      0.32      0.44        31\n",
      "        14.0       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.75       365\n",
      "   macro avg       0.77      0.76      0.75       365\n",
      "weighted avg       0.77      0.75      0.74       365\n",
      "\n",
      "[[23  0  0  0  0  0  0  0  0  0  0  0  0  1  1]\n",
      " [ 3 16  0  0  1  0  0  2  0  1  4  0  2  0  0]\n",
      " [ 1  0 17  0  0  0  0  0  2  0  2  0  0  0  0]\n",
      " [ 0  0  0 21  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 6  1  1  0 13  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 24  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 15  2  0  0  0  0  0  1  0]\n",
      " [ 1  0  0  0  0  0  0 24  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  2  0  1  2  2 12  1  0  0  0  2  2]\n",
      " [ 0  0  3  0  0  0  0  0  2 19  2  0  0  0  0]\n",
      " [ 4  1  0  0  0  0  0  2  0  1 14  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  4  0  0  0  0 18  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  2  0  0  0  0 24  0  0]\n",
      " [ 5  1  0  0  0  0  2  3  0  4  2  0  3 10  1]\n",
      " [ 0  0  0  0  0  0  0  0  2  0  0  0  0  0 22]]\n",
      "accuracy score:  74.52 %\n"
     ]
    }
   ],
   "source": [
    "# testing how the individual model with sampLe parameters scores on test data\n",
    "X_train_os2, x_val, y_train_os2, y_val = train_test_split(X,target,train_size=0.7)\n",
    "print (X_train_os2.shape, y_train_os2.shape)\n",
    "print (x_val.shape,y_val.shape)\n",
    "model = build_model()\n",
    "history = model.fit(X_train_os2, y_train_os2, batch_size=8, epochs=500, validation_data=(x_val, y_val))\n",
    "\n",
    "DL_preds = model.predict(X_test)\n",
    "print (DL_preds.shape)\n",
    "test_results = model.evaluate(X_test,test_targets)\n",
    "for i in range(len(test_results)):\n",
    "    print (model.metrics_names[i],': ',test_results[i])\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "error_metric(y_test,np.argmax(np.round(DL_preds),axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among all the above models we applied on the balanced-oversampled data, the Neural network gives the best accuracy score: 74.52%. If we had some information like which particular class is more important to be correctly classified, then we could have gone with an one-vs -all approach or penalized models over the negatively classified important class, but here we are just taking accuracy into consideration, which also represnts the correctly classified classes over all kinds of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Deep-learning model is most suitable for this problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
